{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è®ºæ–‡19ï¼šå’–å•¡è‡ªåŠ¨æœº - æ·±å…¥æŽ¢è®¨ä¸å¯é€†æ€§\n",
    "**è®ºæ–‡**: Scott Aaronson (2016) - \"å’–å•¡è‡ªåŠ¨æœº\"\n",
    "\n",
    "**æ ¸å¿ƒé—®é¢˜**: ä¸ºä»€ä¹ˆä¸èƒ½æŠŠç‰›å¥¶å’Œå’–å•¡åˆ†å¼€ï¼Ÿä¸å¯é€†æ€§å‘Šè¯‰äº†æˆ‘ä»¬å…³äºŽè®¡ç®—ã€ä¿¡æ¯å’Œæ—¶é—´æœ¬èº«æ€§è´¨çš„ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "## ä¸å¯é€†æ€§ä¹‹è°œ\n",
    "\n",
    "å°†ç‰›å¥¶æ»´å…¥å’–å•¡ä¸­ã€‚çœ‹ç€å®ƒæ‰©æ•£ã€æ—‹è½¬ã€æ··åˆç›´åˆ°å‡åŒ€ã€‚çŽ°åœ¨å°è¯•é€†è½¬å®ƒã€‚**ä½ ä¸èƒ½ã€‚**\n",
    "\n",
    "ä½†è¿™é‡Œæœ‰ä¸ªè°œé¢˜ï¼š\n",
    "- ç‰›é¡¿å®šå¾‹æ˜¯**æ—¶é—´å¯é€†çš„**ï¼šå‘åŽè¿è¡Œå®šå¾‹å®Œå…¨æœ‰æ•ˆ\n",
    "- æ¯ä¸ªåˆ†å­ç¢°æ’žæ˜¯å¯é€†çš„\n",
    "- å¾®è§‚å®šå¾‹ä¸åå‘ä»»ä½•æ—¶é—´æ–¹å‘\n",
    "\n",
    "é‚£ä¹ˆ**ä¸å¯é€†æ€§æ¥è‡ªå“ªé‡Œ**ï¼Ÿ\n",
    "\n",
    "è¿™ä¸ä»…ä»…æ˜¯ç‰©ç†å­¦â€”â€”å®ƒæ·±åˆ»åœ°è”ç³»ç€ï¼š\n",
    "- **è®¡ç®—**ï¼šæˆ‘ä»¬å¯ä»¥é€†è½¬è®¡ç®—å—ï¼Ÿ\n",
    "- **ä¿¡æ¯**ï¼š\"é—å¿˜\"çœŸæ­£æ„å‘³ç€ä»€ä¹ˆï¼Ÿ\n",
    "- **æœºå™¨å­¦ä¹ **ï¼šä¸ºä»€ä¹ˆç¥žç»ç½‘ç»œä¼šåŽ‹ç¼©ä¿¡æ¯ï¼Ÿ\n",
    "- **æ—¶é—´ç®­å¤´**ï¼šä¸ºä»€ä¹ˆæ—¶é—´æœ‰æ–¹å‘ï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "## æœ¬å®žçŽ°\n",
    "\n",
    "æˆ‘ä»¬å°†ä»Žå¤šä¸ªè§’åº¦æŽ¢è®¨ä¸å¯é€†æ€§ï¼š\n",
    "\n",
    "1. **å’–å•¡æ··åˆ**ï¼šæ‰©æ•£å’Œç†µå¢žé•¿\n",
    "2. **ç›¸ç©ºé—´**ï¼šå¯é€†æ€§å­˜åœ¨çš„åœ°æ–¹\n",
    "3. **ç²—ç²’åŒ–**ï¼šæˆ‘ä»¬å¦‚ä½•ä¸¢å¤±ä¿¡æ¯\n",
    "4. **åºžåŠ èŽ±å›žå½’**ï¼šå®‡å®™*å°†*å–æ¶ˆæ··åˆ\n",
    "5. **éº¦å…‹æ–¯éŸ¦å¦–**ï¼šæ™ºèƒ½èƒ½é€†è½¬ç†µå—ï¼Ÿ\n",
    "6. **å…°é“å°”åŽŸç†**ï¼šä¿¡æ¯æ“¦é™¤çš„èƒ½é‡æˆæœ¬\n",
    "7. **è®¡ç®—ä¸å¯é€†æ€§**ï¼šå•å‘å‡½æ•°å’Œå“ˆå¸Œ\n",
    "8. **æœºå™¨å­¦ä¹ **ï¼šä¸ºä»€ä¹ˆç¥žç»ç½‘ç»œåŽ‹ç¼©å’Œé—å¿˜\n",
    "9. **ç¬¬äºŒå®šå¾‹**ï¼šç»Ÿè®¡åŠ›å­¦è§†è§’\n",
    "10. **çŽ°ä»£è§è§£**ï¼šè®¡ç®—çš„çƒ­åŠ›å­¦\n",
    "\n",
    "è¿™è¿œè¶…è®ºæ–‡ 1 å¯¹å¤æ‚åº¦çš„ä»‹ç»ã€‚æˆ‘ä»¬å°†æ·±å…¥æŽ¢è®¨**ä¸ºä»€ä¹ˆ**ä¼šå‡ºçŽ°ä¸å¯é€†æ€§ä»¥åŠå®ƒå¯¹è®¡ç®—å’Œå­¦ä¹ çš„æ„ä¹‰ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬å¼€å§‹å§ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.ndimage import convolve\n",
    "from scipy.stats import entropy as scipy_entropy\n",
    "from typing import Tuple, List, Callable\n",
    "import hashlib\n",
    "from dataclasses import dataclass\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
    "plt.rcParams[\"font.family\"] = [\"Heiti TC\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"\\nReady to explore irreversibility...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬1èŠ‚ï¼šå’–å•¡æ··åˆ - æ‰©æ•£è¿‡ç¨‹\n",
    "\n",
    "ä»Žç»å…¸ä¾‹å­å¼€å§‹ï¼šç‰›å¥¶åœ¨å’–å•¡ä¸­æ‰©æ•£ã€‚\n",
    "\n",
    "## æ‰©æ•£æ–¹ç¨‹\n",
    "\n",
    "æµ“åº¦ $c(x, y, t)$ æ¼”åŒ–éµå¾ªï¼š\n",
    "\n",
    "$$\\frac{\\partial c}{\\partial t} = D \\nabla^2 c = D \\left(\\frac{\\partial^2 c}{\\partial x^2} + \\frac{\\partial^2 c}{\\partial y^2}\\right)$$\n",
    "\n",
    "å…¶ä¸­ $D$ æ˜¯**æ‰©æ•£ç³»æ•°**ã€‚\n",
    "\n",
    "**å…³é”®æ´žå¯Ÿ**ï¼šè¿™ä¸ªæ–¹ç¨‹æœ‰**æ—¶é—´ç®­å¤´**ã€‚å‘åŽè¿è¡Œçœ‹èµ·æ¥ä¸åŒï¼š\n",
    "- å‘å‰ï¼šæµ“åº¦æ‰©æ•£ï¼ˆç‰›å¥¶æ··åˆï¼‰\n",
    "- å‘åŽï¼šæµ“åº¦ä¼šèšé›†ï¼ˆç‰›å¥¶å–æ¶ˆæ··åˆï¼‰\n",
    "\n",
    "ä½†ç¬¬äºŒç§æƒ…æ™¯è¿åçƒ­åŠ›å­¦ç¬¬äºŒå®šå¾‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_coffee_cup(size: int = 64) -> np.ndarray:\n",
    "    \"\"\"Initialize a 'coffee cup' with a drop of milk in the center.\n",
    "    \n",
    "    Returns:\n",
    "        concentration: 2D array where 1 = milk, 0 = coffee\n",
    "    \"\"\"\n",
    "    cup = np.zeros((size, size))\n",
    "    \n",
    "    # Add a drop of milk in the center\n",
    "    center = size // 2\n",
    "    radius = size // 8\n",
    "    \n",
    "    y, x = np.ogrid[:size, :size]\n",
    "    mask = (x - center)**2 + (y - center)**2 <= radius**2\n",
    "    cup[mask] = 1.0\n",
    "    \n",
    "    return cup\n",
    "\n",
    "\n",
    "def diffusion_step(concentration: np.ndarray, D: float = 0.1) -> np.ndarray:\n",
    "    \"\"\"One timestep of diffusion using finite differences.\n",
    "    \n",
    "    Args:\n",
    "        concentration: Current concentration field\n",
    "        D: Diffusion coefficient\n",
    "    \n",
    "    Returns:\n",
    "        New concentration after one timestep\n",
    "    \"\"\"\n",
    "    # Laplacian kernel (discrete âˆ‡Â²)\n",
    "    kernel = np.array([[0, 1, 0],\n",
    "                       [1, -4, 1],\n",
    "                       [0, 1, 0]])\n",
    "    \n",
    "    # Apply Laplacian\n",
    "    laplacian = convolve(concentration, kernel, mode='constant', cval=0.0)\n",
    "    \n",
    "    # Update: c(t+Î”t) = c(t) + DÂ·Î”tÂ·âˆ‡Â²c\n",
    "    dt = 0.1\n",
    "    new_concentration = concentration + D * dt * laplacian\n",
    "    \n",
    "    # Keep concentrations in valid range\n",
    "    new_concentration = np.clip(new_concentration, 0, 1)\n",
    "    \n",
    "    return new_concentration\n",
    "\n",
    "\n",
    "def simulate_coffee_mixing(steps: int = 200, D: float = 0.1) -> List[np.ndarray]:\n",
    "    \"\"\"Simulate coffee mixing over time.\n",
    "    \n",
    "    Returns:\n",
    "        List of concentration fields at each timestep\n",
    "    \"\"\"\n",
    "    cup = initialize_coffee_cup()\n",
    "    history = [cup.copy()]\n",
    "    \n",
    "    for _ in range(steps):\n",
    "        cup = diffusion_step(cup, D)\n",
    "        history.append(cup.copy())\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# Simulate mixing\n",
    "print(\"Simulating coffee mixing...\\n\")\n",
    "mixing_history = simulate_coffee_mixing(steps=200)\n",
    "\n",
    "# Show key frames\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "timesteps = [0, 25, 50, 100, 200]\n",
    "\n",
    "for ax, t in zip(axes, timesteps):\n",
    "    im = ax.imshow(mixing_history[t], cmap='RdYlBu_r', vmin=0, vmax=1)\n",
    "    ax.set_title(f't = {t}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.colorbar(im, ax=axes, label='Milk Concentration', fraction=0.046)\n",
    "plt.suptitle('Coffee Mixing: Irreversible Diffusion', fontsize=14, fontweight='bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observation: The milk spreads out and can never spontaneously unmix!\")\n",
    "print(\"\\nâœ“ Diffusion simulation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬2èŠ‚ï¼šç†µå¢žé•¿ - é‡åŒ–ä¸å¯é€†æ€§\n",
    "\n",
    "**ç†µ**æµ‹é‡æ— åºæˆ–\"æ‰©æ•£ç¨‹åº¦\"ã€‚éšç€ç‰›å¥¶æ··åˆï¼Œç†µå¢žåŠ ã€‚\n",
    "\n",
    "## é¦™å†œç†µ\n",
    "\n",
    "å°†æ¯å­åˆ†æˆè‹¥å¹²ç®±ã€‚é¦™å†œç†µä¸ºï¼š\n",
    "\n",
    "$$H = -\\sum_i p_i \\log_2 p_i$$\n",
    "\n",
    "å…¶ä¸­ $p_i$ æ˜¯åœ¨ç®±å­ $i$ ä¸­æ‰¾åˆ°ç‰›å¥¶çš„æ¦‚çŽ‡ã€‚\n",
    "\n",
    "## çƒ­åŠ›å­¦ç†µ\n",
    "\n",
    "ä¸Žä¸Žå®è§‚æ€ä¸€è‡´çš„å¾®è§‚æ€æ•°é‡ $\\Omega$ ç›¸å…³ï¼š\n",
    "\n",
    "$$S = k_B \\ln \\Omega$$\n",
    "\n",
    "**çƒ­åŠ›å­¦ç¬¬äºŒå®šå¾‹**ï¼šåœ¨å­¤ç«‹ç³»ç»Ÿä¸­ï¼Œç†µæ°¸ä¸å‡å°‘ï¼š\n",
    "\n",
    "$$\\frac{dS}{dt} \\geq 0$$\n",
    "\n",
    "è¿™å°±æ˜¯æ—¶é—´ç®­å¤´ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shannon_entropy(concentration: np.ndarray, num_bins: int = 10) -> float:\n",
    "    \"\"\"Compute Shannon entropy of concentration distribution.\n",
    "    \n",
    "    Args:\n",
    "        concentration: 2D concentration field\n",
    "        num_bins: Number of bins for histogram\n",
    "    \n",
    "    Returns:\n",
    "        Shannon entropy in bits\n",
    "    \"\"\"\n",
    "    # Flatten and create histogram\n",
    "    flat = concentration.flatten()\n",
    "    hist, _ = np.histogram(flat, bins=num_bins, range=(0, 1), density=True)\n",
    "    \n",
    "    # Normalize to probabilities\n",
    "    hist = hist / hist.sum()\n",
    "    \n",
    "    # Compute Shannon entropy\n",
    "    return scipy_entropy(hist, base=2)\n",
    "\n",
    "\n",
    "def compute_spatial_entropy(concentration: np.ndarray) -> float:\n",
    "    \"\"\"Compute spatial entropy (variance of concentration).\n",
    "    \n",
    "    As mixing proceeds, variance decreases (becomes more uniform).\n",
    "    So we use negative variance as a measure of mixing.\n",
    "    \"\"\"\n",
    "    return -np.var(concentration)\n",
    "\n",
    "\n",
    "def compute_mixing_quality(concentration: np.ndarray) -> float:\n",
    "    \"\"\"Compute how well-mixed the cup is.\n",
    "    \n",
    "    Returns:\n",
    "        Value in [0, 1] where 1 = perfectly mixed\n",
    "    \"\"\"\n",
    "    # Perfect mixing = all pixels have same concentration\n",
    "    mean_concentration = concentration.mean()\n",
    "    variance = np.var(concentration)\n",
    "    \n",
    "    # Maximum variance (for this mean) is when half is 0, half is 2*mean\n",
    "    max_variance = mean_concentration * (1 - mean_concentration)\n",
    "    \n",
    "    if max_variance == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    return 1 - (variance / max_variance)\n",
    "\n",
    "\n",
    "# Compute entropy over time\n",
    "print(\"Computing entropy over time...\\n\")\n",
    "\n",
    "shannon_entropies = [compute_shannon_entropy(cup) for cup in mixing_history]\n",
    "spatial_entropies = [compute_spatial_entropy(cup) for cup in mixing_history]\n",
    "mixing_qualities = [compute_mixing_quality(cup) for cup in mixing_history]\n",
    "\n",
    "# Plot entropy growth\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: Shannon entropy\n",
    "axes[0].plot(shannon_entropies, linewidth=2, color='darkblue')\n",
    "axes[0].set_xlabel('Time Step', fontsize=11)\n",
    "axes[0].set_ylabel('Shannon Entropy (bits)', fontsize=11)\n",
    "axes[0].set_title('Information Entropy Growth', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(y=shannon_entropies[0], color='red', linestyle='--', alpha=0.5, label='Initial')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot 2: Spatial entropy (negative variance)\n",
    "axes[1].plot(spatial_entropies, linewidth=2, color='darkgreen')\n",
    "axes[1].set_xlabel('Time Step', fontsize=11)\n",
    "axes[1].set_ylabel('Spatial Entropy (-Variance)', fontsize=11)\n",
    "axes[1].set_title('Spatial Disorder Growth', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Mixing quality\n",
    "axes[2].plot(mixing_qualities, linewidth=2, color='darkorange')\n",
    "axes[2].set_xlabel('Time Step', fontsize=11)\n",
    "axes[2].set_ylabel('Mixing Quality', fontsize=11)\n",
    "axes[2].set_title('Approach to Equilibrium', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='Perfect mixing')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial Shannon entropy: {shannon_entropies[0]:.3f} bits\")\n",
    "print(f\"Final Shannon entropy:   {shannon_entropies[-1]:.3f} bits\")\n",
    "print(f\"Entropy increase:        {shannon_entropies[-1] - shannon_entropies[0]:.3f} bits\")\n",
    "print(f\"\\nFinal mixing quality:    {mixing_qualities[-1]:.1%}\")\n",
    "\n",
    "print(\"\\nðŸ”‘ Key insight: Entropy monotonically increases!\")\n",
    "print(\"   This is the second law of thermodynamics in action.\")\n",
    "print(\"\\nâœ“ Entropy analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬3èŠ‚ï¼šç›¸ç©ºé—´ä¸Žåˆ˜ç»´å°”å®šç†\n",
    "\n",
    "è¿™é‡Œå˜å¾—æ·±åˆ»ï¼š**ä¸ºä»€ä¹ˆç†µå¢žåŠ å¦‚æžœå¾®è§‚å®šå¾‹æ˜¯å¯é€†çš„ï¼Ÿ**\n",
    "\n",
    "## ç›¸ç©ºé—´\n",
    "\n",
    "è€ƒè™‘ä¸€ä¸ªæœ‰ $N$ ä¸ªç²’å­çš„ç³»ç»Ÿã€‚**ç›¸ç©ºé—´**æ˜¯æ‰€æœ‰ä½ç½®å’ŒåŠ¨é‡çš„ 6N ç»´ç©ºé—´ï¼š\n",
    "\n",
    "$$\\Gamma = (x_1, y_1, z_1, p_{x1}, p_{y1}, p_{z1}, \\ldots, x_N, y_N, z_N, p_{xN}, p_{yN}, p_{zN})$$\n",
    "\n",
    "ç›¸ç©ºé—´ä¸­çš„ä¸€ç‚¹æ˜¯ä¸€ä¸ª**å¾®è§‚æ€**â€”â€”ç³»ç»Ÿçš„å®Œæ•´è§„èŒƒã€‚\n",
    "\n",
    "## åˆ˜ç»´å°”å®šç†\n",
    "\n",
    "**åˆ˜ç»´å°”å®šç†**æŒ‡å‡ºç›¸ç©ºé—´ä½“ç§¯å®ˆæ’ï¼š\n",
    "\n",
    "$$\\frac{d}{dt} \\int_{V} d\\Gamma = 0$$\n",
    "\n",
    "è¿™æ„å‘³ç€ï¼š\n",
    "- **å¾®è§‚ä¸Šï¼ŒåŠ¨åŠ›å­¦æ˜¯å¯é€†çš„**\n",
    "- ç›¸ç©ºé—´ä½“ç§¯ä¸æ”¹å˜\n",
    "- ä¿¡æ¯å®ˆæ’\n",
    "\n",
    "## è§£å†³æ–¹æ¡ˆï¼šç²—ç²’åŒ–\n",
    "\n",
    "å…³é”®æ˜¯**ç²—ç²’åŒ–**ï¼šæˆ‘ä»¬æ— æ³•è·Ÿè¸ªå•ä¸ªåˆ†å­ï¼Œæ‰€ä»¥å°†é™„è¿‘çš„å¾®è§‚æ€åˆ†ç»„ä¸º**å®è§‚æ€**ã€‚\n",
    "\n",
    "- **å¾®è§‚æ€**ï¼šæ‰€æœ‰åˆ†å­çš„ç²¾ç¡®ä½ç½®/åŠ¨é‡ï¼ˆå¯é€†ï¼‰\n",
    "- **å®è§‚æ€**ï¼šç²—ç•¥æè¿°ï¼Œå¦‚\"æ¸©åº¦\"æˆ–\"æµ“åº¦\"ï¼ˆä¸å¯é€†ï¼‰\n",
    "\n",
    "**ç†µå¢žåŠ **æ˜¯å› ä¸ºï¼š\n",
    "1. è®¸å¤šå¾®è§‚æ€æ˜ å°„åˆ°åŒä¸€å®è§‚æ€\n",
    "2. æ¼”åŒ–è¶‹å‘äºŽå…·æœ‰æ›´å¤šå¾®è§‚æ€çš„å®è§‚æ€\n",
    "3. ç²—ç²’åŒ–æ—¶æˆ‘ä»¬ä¸¢å¤±ä¿¡æ¯\n",
    "\n",
    "è®©æˆ‘ä»¬æ¨¡æ‹Ÿä¸€ä¸‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Particle:\n",
    "    \"\"\"A particle in 2D phase space.\"\"\"\n",
    "    x: float\n",
    "    y: float\n",
    "    vx: float\n",
    "    vy: float\n",
    "\n",
    "\n",
    "def initialize_particles(num_particles: int = 100, region: str = 'left') -> List[Particle]:\n",
    "    \"\"\"Initialize particles in a specific region.\n",
    "    \n",
    "    Args:\n",
    "        num_particles: Number of particles\n",
    "        region: 'left' or 'right' half of box\n",
    "    \"\"\"\n",
    "    particles = []\n",
    "    \n",
    "    for _ in range(num_particles):\n",
    "        if region == 'left':\n",
    "            x = np.random.uniform(0.1, 0.4)\n",
    "        else:\n",
    "            x = np.random.uniform(0.6, 0.9)\n",
    "        \n",
    "        y = np.random.uniform(0.1, 0.9)\n",
    "        \n",
    "        # Random velocities\n",
    "        speed = 0.02\n",
    "        angle = np.random.uniform(0, 2*np.pi)\n",
    "        vx = speed * np.cos(angle)\n",
    "        vy = speed * np.sin(angle)\n",
    "        \n",
    "        particles.append(Particle(x, y, vx, vy))\n",
    "    \n",
    "    return particles\n",
    "\n",
    "\n",
    "def update_particles(particles: List[Particle], dt: float = 1.0) -> List[Particle]:\n",
    "    \"\"\"Update particle positions (free motion with reflecting boundaries).\"\"\"\n",
    "    new_particles = []\n",
    "    \n",
    "    for p in particles:\n",
    "        # Update position\n",
    "        new_x = p.x + p.vx * dt\n",
    "        new_y = p.y + p.vy * dt\n",
    "        new_vx, new_vy = p.vx, p.vy\n",
    "        \n",
    "        # Reflecting boundaries\n",
    "        if new_x < 0 or new_x > 1:\n",
    "            new_vx = -new_vx\n",
    "            new_x = np.clip(new_x, 0, 1)\n",
    "        \n",
    "        if new_y < 0 or new_y > 1:\n",
    "            new_vy = -new_vy\n",
    "            new_y = np.clip(new_y, 0, 1)\n",
    "        \n",
    "        new_particles.append(Particle(new_x, new_y, new_vx, new_vy))\n",
    "    \n",
    "    return new_particles\n",
    "\n",
    "\n",
    "def compute_macrostate(particles: List[Particle], num_bins: int = 4) -> np.ndarray:\n",
    "    \"\"\"Coarse-grain particles into spatial bins.\n",
    "    \n",
    "    Returns:\n",
    "        2D histogram of particle counts\n",
    "    \"\"\"\n",
    "    positions = np.array([[p.x, p.y] for p in particles])\n",
    "    \n",
    "    hist, _, _ = np.histogram2d(\n",
    "        positions[:, 0], positions[:, 1],\n",
    "        bins=num_bins,\n",
    "        range=[[0, 1], [0, 1]]\n",
    "    )\n",
    "    \n",
    "    return hist\n",
    "\n",
    "\n",
    "def compute_macrostate_entropy(macrostate: np.ndarray) -> float:\n",
    "    \"\"\"Compute entropy of a macrostate.\"\"\"\n",
    "    # Flatten and normalize\n",
    "    counts = macrostate.flatten()\n",
    "    if counts.sum() == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    probs = counts / counts.sum()\n",
    "    probs = probs[probs > 0]  # Remove zeros\n",
    "    \n",
    "    return -np.sum(probs * np.log2(probs))\n",
    "\n",
    "\n",
    "# Simulate particle mixing\n",
    "print(\"Simulating particle mixing with coarse-graining...\\n\")\n",
    "\n",
    "# Initialize particles on left side\n",
    "particles = initialize_particles(num_particles=200, region='left')\n",
    "\n",
    "# Simulate\n",
    "num_steps = 500\n",
    "particle_history = [particles]\n",
    "macrostate_history = []\n",
    "macrostate_entropies = []\n",
    "\n",
    "for step in range(num_steps):\n",
    "    particles = update_particles(particles)\n",
    "    particle_history.append([Particle(p.x, p.y, p.vx, p.vy) for p in particles])\n",
    "    \n",
    "    # Compute macrostate every 10 steps\n",
    "    if step % 10 == 0:\n",
    "        macrostate = compute_macrostate(particles)\n",
    "        macrostate_history.append(macrostate)\n",
    "        macrostate_entropies.append(compute_macrostate_entropy(macrostate))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Top row: Microstate (particle positions)\n",
    "timesteps_vis = [0, 100, 500]\n",
    "for idx, t in enumerate(timesteps_vis):\n",
    "    ax = axes[0, idx]\n",
    "    ps = particle_history[t]\n",
    "    positions = np.array([[p.x, p.y] for p in ps])\n",
    "    \n",
    "    ax.scatter(positions[:, 0], positions[:, 1], s=10, alpha=0.6, color='blue')\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'Microstate at t={t}', fontweight='bold')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "\n",
    "# Bottom row: Macrostate (coarse-grained)\n",
    "macro_timesteps = [0, 10, 50]\n",
    "for idx, mt in enumerate(macro_timesteps):\n",
    "    ax = axes[1, idx]\n",
    "    im = ax.imshow(macrostate_history[mt].T, cmap='Blues', origin='lower', \n",
    "                   extent=[0, 1, 0, 1], vmin=0, vmax=macrostate_history[0].max())\n",
    "    ax.set_title(f'Macrostate at t={mt*10}\\nS={macrostate_entropies[mt]:.2f} bits', \n",
    "                fontweight='bold')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    plt.colorbar(im, ax=ax, label='Particle count')\n",
    "\n",
    "plt.suptitle('Microscopic Reversibility vs Macroscopic Irreversibility', \n",
    "            fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot entropy growth\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.arange(len(macrostate_entropies)) * 10, macrostate_entropies, \n",
    "         linewidth=2, color='darkred')\n",
    "plt.xlabel('Time Step', fontsize=12)\n",
    "plt.ylabel('Macroscopic Entropy (bits)', fontsize=12)\n",
    "plt.title('Entropy Growth Despite Microscopic Reversibility', fontsize=13, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ”‘ Key insight: Liouville's theorem guarantees microscopic reversibility.\")\n",
    "print(\"   But macroscopic entropy STILL increases due to coarse-graining!\")\n",
    "print(\"\\n   â€¢ Microstate: Exact particle positions (reversible)\")\n",
    "print(\"   â€¢ Macrostate: Binned particle counts (irreversible)\")\n",
    "print(\"   â€¢ Many microstates â†’ same macrostate\")\n",
    "print(\"   â€¢ Evolution explores more microstates over time\")\n",
    "print(\"\\nâœ“ Phase space analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬4èŠ‚ï¼šåºžåŠ èŽ±å›žå½’ - å®‡å®™å°†ä¼šå–æ¶ˆæ··åˆï¼\n",
    "\n",
    "è¿™é‡Œæœ‰ä¸€ä¸ªä»¤äººéœ‡æƒŠçš„äº‹å®žï¼š**åºžåŠ èŽ±å›žå½’å®šç†**æŒ‡å‡ºï¼Œä»»ä½•æœ‰é™ç³»ç»Ÿæœ€ç»ˆå°†ä»»æ„æŽ¥è¿‘å…¶åˆå§‹çŠ¶æ€ã€‚\n",
    "\n",
    "## å®šç†\n",
    "\n",
    "å¯¹äºŽ**æœ‰é™**ç›¸ç©ºé—´ä½“ç§¯ï¼Œå‡ ä¹Žæ¯ä¸ªåˆå§‹æ¡ä»¶éƒ½ä¼šæ— é™æ¬¡åœ°å¾ªçŽ¯ï¼š\n",
    "\n",
    "$$\\lim_{t \\to \\infty} \\inf \\, d(\\Gamma(t), \\Gamma(0)) = 0$$\n",
    "\n",
    "è¿™æ„å‘³ç€ï¼š\n",
    "- ç»™å®šè¶³å¤Ÿæ—¶é—´ï¼Œå’–å•¡**å°†**å–æ¶ˆæ··åˆï¼\n",
    "- ç²’å­**å°†**è¿”å›žåˆ°å…¶åˆå§‹é…ç½®ï¼\n",
    "\n",
    "## é™·é˜±ï¼šå›žå½’æ—¶é—´\n",
    "\n",
    "ä½ éœ€è¦ç­‰å¾…å¤šä¹…ï¼Ÿå¯¹äºŽ $N$ ä¸ªç²’å­ï¼š\n",
    "\n",
    "$$t_{\\text{recurrence}} \\sim e^{N}$$\n",
    "\n",
    "å¯¹äºŽä¸€ä¸ªæœ‰ $N \\sim 10^{23}$ ä¸ªåˆ†å­çš„å’–å•¡æ¯ï¼š\n",
    "\n",
    "$$t_{\\text{recurrence}} \\sim 10^{10^{23}} \\text{ ç§’}$$\n",
    "\n",
    "è¿™**è¿œå¤§äºŽ**å®‡å®™å¹´é¾„ï¼ˆ$\\sim 10^{17}$ ç§’ï¼‰ã€‚\n",
    "\n",
    "**å®žé™…ä¸å¯é€†æ€§**ï¼šç³»ç»Ÿç†è®ºä¸Šå¯é€†ï¼Œä½†å®žé™…ä¸Šä¸å¯é€†ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªå°ç³»ç»Ÿæ¼”ç¤ºä¸€ä¸‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_phase_space_system(num_states: int = 8, num_steps: int = 10000) -> Tuple[List[int], List[int]]:\n",
    "    \"\"\"Simulate a simple deterministic system on a finite phase space.\n",
    "    \n",
    "    Args:\n",
    "        num_states: Size of phase space (small for demonstration)\n",
    "        num_steps: Number of steps to simulate\n",
    "    \n",
    "    Returns:\n",
    "        states: List of states visited\n",
    "        recurrence_times: Time to return to initial state\n",
    "    \"\"\"\n",
    "    # Define a deterministic evolution rule\n",
    "    # Simple example: state_next = (a * state + b) mod num_states\n",
    "    a, b = 3, 1  # Parameters chosen to give interesting dynamics\n",
    "    \n",
    "    initial_state = 0\n",
    "    state = initial_state\n",
    "    states = [state]\n",
    "    recurrence_times = []\n",
    "    \n",
    "    for step in range(1, num_steps):\n",
    "        # Deterministic evolution\n",
    "        state = (a * state + b) % num_states\n",
    "        states.append(state)\n",
    "        \n",
    "        # Check for recurrence\n",
    "        if state == initial_state:\n",
    "            recurrence_times.append(step)\n",
    "    \n",
    "    return states, recurrence_times\n",
    "\n",
    "\n",
    "def estimate_recurrence_time_scaling() -> Tuple[List[int], List[float]]:\n",
    "    \"\"\"Estimate how recurrence time scales with system size.\"\"\"\n",
    "    sizes = [4, 8, 16, 32, 64, 128]\n",
    "    avg_recurrence_times = []\n",
    "    \n",
    "    for size in sizes:\n",
    "        _, rec_times = simple_phase_space_system(num_states=size, num_steps=size*20)\n",
    "        if len(rec_times) > 0:\n",
    "            avg_time = np.mean(np.diff([0] + rec_times))\n",
    "        else:\n",
    "            avg_time = size * 10  # Estimate\n",
    "        avg_recurrence_times.append(avg_time)\n",
    "    \n",
    "    return sizes, avg_recurrence_times\n",
    "\n",
    "\n",
    "# Demonstrate PoincarÃ© recurrence\n",
    "print(\"Demonstrating PoincarÃ© recurrence...\\n\")\n",
    "\n",
    "num_states = 16\n",
    "states, recurrence_times = simple_phase_space_system(num_states=num_states, num_steps=200)\n",
    "\n",
    "print(f\"System with {num_states} states\")\n",
    "print(f\"Initial state: {states[0]}\")\n",
    "print(f\"\\nRecurrences found at timesteps: {recurrence_times[:5]}...\")\n",
    "\n",
    "if len(recurrence_times) > 1:\n",
    "    period = recurrence_times[1] - recurrence_times[0]\n",
    "    print(f\"Recurrence period: {period} steps\")\n",
    "\n",
    "# Visualize state evolution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: State trajectory\n",
    "ax = axes[0, 0]\n",
    "ax.plot(states[:200], linewidth=1.5, color='darkblue')\n",
    "for rt in recurrence_times:\n",
    "    if rt < 200:\n",
    "        ax.axvline(rt, color='red', alpha=0.3, linestyle='--')\n",
    "ax.set_xlabel('Time Step', fontsize=11)\n",
    "ax.set_ylabel('State', fontsize=11)\n",
    "ax.set_title(f'State Evolution (Red lines = recurrence)', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: State histogram\n",
    "ax = axes[0, 1]\n",
    "ax.hist(states, bins=num_states, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax.set_xlabel('State', fontsize=11)\n",
    "ax.set_ylabel('Frequency', fontsize=11)\n",
    "ax.set_title('State Distribution (Should be uniform)', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: Recurrence time scaling\n",
    "ax = axes[1, 0]\n",
    "sizes, rec_times_avg = estimate_recurrence_time_scaling()\n",
    "ax.semilogy(sizes, rec_times_avg, 'o-', linewidth=2, markersize=8, color='darkgreen', label='Observed')\n",
    "# Fit exponential\n",
    "log_rec_times = np.log(rec_times_avg)\n",
    "coeffs = np.polyfit(sizes, log_rec_times, 1)\n",
    "fit_line = np.exp(coeffs[1]) * np.exp(coeffs[0] * np.array(sizes))\n",
    "ax.semilogy(sizes, fit_line, '--', linewidth=2, color='red', label=f'Exponential fit')\n",
    "ax.set_xlabel('System Size (# states)', fontsize=11)\n",
    "ax.set_ylabel('Average Recurrence Time', fontsize=11)\n",
    "ax.set_title('Exponential Growth of Recurrence Time', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Extrapolation to realistic systems\n",
    "ax = axes[1, 1]\n",
    "N_values = np.array([10, 100, 1000, 10000, 1e23])  # Up to coffee cup\n",
    "t_rec_estimates = np.exp(N_values * 0.5)  # Very rough estimate\n",
    "universe_age = 4.3e17  # seconds\n",
    "\n",
    "ax.loglog(N_values[:-1], t_rec_estimates[:-1], 'o-', linewidth=2, markersize=8, color='purple')\n",
    "ax.axhline(universe_age, color='red', linestyle='--', linewidth=2, label='Age of universe')\n",
    "ax.set_xlabel('Number of Particles', fontsize=11)\n",
    "ax.set_ylabel('Recurrence Time (seconds)', fontsize=11)\n",
    "ax.set_title('Why Coffee Never Unmixes', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "ax.text(100, 1e20, f'Coffee cup:\\n$N \\\\sim 10^{{23}}$\\n$t_{{rec}} \\\\sim 10^{{10^{{23}}}}$ s', \n",
    "        fontsize=10, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ”‘ Key insights:\")\n",
    "print(\"   1. PoincarÃ© recurrence IS real - finite systems eventually recur\")\n",
    "print(\"   2. But recurrence time grows EXPONENTIALLY with system size\")\n",
    "print(f\"   3. For coffee (~10Â²Â³ particles): t_rec ~ 10^(10^23) seconds\")\n",
    "print(f\"   4. Universe age: ~10^17 seconds\")\n",
    "print(\"   5. So coffee will unmix... after waiting 10^(10^23) times the age of the universe!\")\n",
    "print(\"\\n   This is why irreversibility is PRACTICAL even though dynamics are reversible.\")\n",
    "print(\"\\nâœ“ PoincarÃ© recurrence analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬5èŠ‚ï¼šéº¦å…‹æ–¯éŸ¦å¦– - æ™ºèƒ½èƒ½é€†è½¬ç†µå—ï¼Ÿ\n",
    "\n",
    "**éº¦å…‹æ–¯éŸ¦å¦–**æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ç¬¬äºŒå®šå¾‹çš„æ€æƒ³å®žéªŒã€‚\n",
    "\n",
    "## è®¾ç½®\n",
    "\n",
    "1. ç›’å­åˆ†æˆä¸¤éƒ¨åˆ†çš„ç›’å­ï¼Œä¸­é—´æœ‰ä¸€æ‰‡é—¨\n",
    "2. æ°”ä½“åˆ†å­éšæœºç§»åŠ¨\n",
    "3. ä¸€ä¸ª\"å¦–\"æ“ä½œé—¨ï¼š\n",
    "   - å‘å³å¼€çš„é—¨ï¼šå¿«é€Ÿåˆ†å­\n",
    "   - å‘å·¦å¼€çš„é—¨ï¼šæ…¢é€Ÿåˆ†å­\n",
    "4. ç»“æžœï¼šå³è¾¹æ˜¯çƒ­æ°”ï¼Œå·¦è¾¹æ˜¯å†·æ°”ï¼ˆç†µå‡å°‘ï¼ï¼‰\n",
    "\n",
    "## æ‚–è®º\n",
    "\n",
    "å¦–ä¼¼ä¹Ž**è¿åç¬¬äºŒå®šå¾‹**ï¼Œä¸åšåŠŸå°±èƒ½å‡å°‘ç†µã€‚\n",
    "\n",
    "## è§£å†³æ–¹æ¡ˆï¼šå…°é“å°”åŽŸç†\n",
    "\n",
    "å¦–å¿…é¡»**æµ‹é‡**åˆ†å­é€Ÿåº¦å¹¶**å­˜å‚¨**æ­¤ä¿¡æ¯ã€‚æœ€ç»ˆï¼Œå®ƒå¿…é¡»**æ“¦é™¤**è®°å¿†ä»¥ç»§ç»­æ“ä½œã€‚\n",
    "\n",
    "**å…°é“å°”åŽŸç†**ï¼ˆ1961ï¼‰ï¼šæ“¦é™¤ä¸€ä½ä¿¡æ¯è‡³å°‘éœ€è¦è€—æ•£ï¼š\n",
    "\n",
    "$$E_{\\text{min}} = k_B T \\ln 2$$\n",
    "\n",
    "çš„èƒ½é‡ä½œä¸ºçƒ­é‡ã€‚\n",
    "\n",
    "è¿™çƒ­é‡è€—æ•£**ç²¾ç¡®è¡¥å¿**äº†å¦–å‡å°‘çš„ç†µï¼\n",
    "\n",
    "**æ·±åˆ»å«ä¹‰**ï¼š**ä¿¡æ¯æ˜¯ç‰©ç†çš„**ã€‚è®¡ç®—æœ‰çƒ­åŠ›å­¦æˆæœ¬ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬æ¨¡æ‹Ÿéº¦å…‹æ–¯éŸ¦å¦–ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GasParticle:\n",
    "    \"\"\"A gas particle with position and velocity.\"\"\"\n",
    "    x: float\n",
    "    y: float\n",
    "    vx: float\n",
    "    vy: float\n",
    "    \n",
    "    def speed(self) -> float:\n",
    "        return np.sqrt(self.vx**2 + self.vy**2)\n",
    "\n",
    "\n",
    "class MaxwellsDemon:\n",
    "    \"\"\"Simulates Maxwell's demon thought experiment.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_particles: int = 100):\n",
    "        self.num_particles = num_particles\n",
    "        self.particles = self._initialize_particles()\n",
    "        self.door_position = 0.5  # Middle of box\n",
    "        self.memory = []  # Demon's memory\n",
    "        self.entropy_cost = 0.0  # Cost of erasure\n",
    "    \n",
    "    def _initialize_particles(self) -> List[GasParticle]:\n",
    "        \"\"\"Initialize particles with Maxwell-Boltzmann distribution.\"\"\"\n",
    "        particles = []\n",
    "        for _ in range(self.num_particles):\n",
    "            x = np.random.uniform(0.1, 0.9)\n",
    "            y = np.random.uniform(0.1, 0.9)\n",
    "            \n",
    "            # Maxwell-Boltzmann velocity distribution\n",
    "            speed = np.random.rayleigh(0.02)\n",
    "            angle = np.random.uniform(0, 2*np.pi)\n",
    "            vx = speed * np.cos(angle)\n",
    "            vy = speed * np.sin(angle)\n",
    "            \n",
    "            particles.append(GasParticle(x, y, vx, vy))\n",
    "        return particles\n",
    "    \n",
    "    def update_without_demon(self, dt: float = 1.0):\n",
    "        \"\"\"Update particles without demon (natural evolution).\"\"\"\n",
    "        new_particles = []\n",
    "        for p in self.particles:\n",
    "            new_x = p.x + p.vx * dt\n",
    "            new_y = p.y + p.vy * dt\n",
    "            new_vx, new_vy = p.vx, p.vy\n",
    "            \n",
    "            # Reflecting boundaries\n",
    "            if new_x < 0 or new_x > 1:\n",
    "                new_vx = -new_vx\n",
    "                new_x = np.clip(new_x, 0, 1)\n",
    "            if new_y < 0 or new_y > 1:\n",
    "                new_vy = -new_vy\n",
    "                new_y = np.clip(new_y, 0, 1)\n",
    "            \n",
    "            new_particles.append(GasParticle(new_x, new_y, new_vx, new_vy))\n",
    "        \n",
    "        self.particles = new_particles\n",
    "    \n",
    "    def update_with_demon(self, dt: float = 1.0, threshold_speed: float = 0.025):\n",
    "        \"\"\"Update particles with demon operating the door.\"\"\"\n",
    "        new_particles = []\n",
    "        \n",
    "        for p in self.particles:\n",
    "            new_x = p.x + p.vx * dt\n",
    "            new_y = p.y + p.vy * dt\n",
    "            new_vx, new_vy = p.vx, p.vy\n",
    "            \n",
    "            # Check if particle crosses middle partition\n",
    "            crosses_door = (p.x < self.door_position <= new_x) or (p.x > self.door_position >= new_x)\n",
    "            \n",
    "            if crosses_door and 0.4 < new_y < 0.6:  # Door is in middle vertically\n",
    "                # Demon measures speed and decides\n",
    "                speed = p.speed()\n",
    "                self.memory.append(speed)  # Store measurement (costs memory)\n",
    "                \n",
    "                # Demon's rule:\n",
    "                # - Fast particles go right\n",
    "                # - Slow particles go left\n",
    "                going_right = new_x > p.x\n",
    "                is_fast = speed > threshold_speed\n",
    "                \n",
    "                if (going_right and not is_fast) or (not going_right and is_fast):\n",
    "                    # Reflect the particle (close door)\n",
    "                    new_vx = -new_vx\n",
    "                    new_x = p.x\n",
    "            \n",
    "            # Regular boundaries\n",
    "            if new_x < 0 or new_x > 1:\n",
    "                new_vx = -new_vx\n",
    "                new_x = np.clip(new_x, 0, 1)\n",
    "            if new_y < 0 or new_y > 1:\n",
    "                new_vy = -new_vy\n",
    "                new_y = np.clip(new_y, 0, 1)\n",
    "            \n",
    "            new_particles.append(GasParticle(new_x, new_y, new_vx, new_vy))\n",
    "        \n",
    "        self.particles = new_particles\n",
    "        \n",
    "        # Landauer erasure cost\n",
    "        if len(self.memory) > 50:  # Erase old memories\n",
    "            bits_erased = len(self.memory) - 50\n",
    "            self.entropy_cost += bits_erased * np.log(2)  # k_B T ln(2) per bit\n",
    "            self.memory = self.memory[-50:]\n",
    "    \n",
    "    def compute_temperature_difference(self) -> float:\n",
    "        \"\"\"Compute temperature difference between left and right chambers.\"\"\"\n",
    "        left_particles = [p for p in self.particles if p.x < self.door_position]\n",
    "        right_particles = [p for p in self.particles if p.x >= self.door_position]\n",
    "        \n",
    "        if len(left_particles) == 0 or len(right_particles) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Temperature âˆ average kinetic energy âˆ average speedÂ²\n",
    "        left_temp = np.mean([p.speed()**2 for p in left_particles])\n",
    "        right_temp = np.mean([p.speed()**2 for p in right_particles])\n",
    "        \n",
    "        return right_temp - left_temp\n",
    "\n",
    "\n",
    "# Simulate with and without demon\n",
    "print(\"Simulating Maxwell's demon...\\n\")\n",
    "\n",
    "# Without demon\n",
    "system_no_demon = MaxwellsDemon(num_particles=150)\n",
    "temp_diffs_no_demon = []\n",
    "\n",
    "for _ in range(300):\n",
    "    system_no_demon.update_without_demon()\n",
    "    temp_diffs_no_demon.append(system_no_demon.compute_temperature_difference())\n",
    "\n",
    "# With demon\n",
    "system_with_demon = MaxwellsDemon(num_particles=150)\n",
    "temp_diffs_with_demon = []\n",
    "entropy_costs = []\n",
    "\n",
    "for _ in range(300):\n",
    "    system_with_demon.update_with_demon()\n",
    "    temp_diffs_with_demon.append(system_with_demon.compute_temperature_difference())\n",
    "    entropy_costs.append(system_with_demon.entropy_cost)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Temperature difference without demon\n",
    "axes[0, 0].plot(temp_diffs_no_demon, linewidth=2, color='blue', alpha=0.7)\n",
    "axes[0, 0].axhline(0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[0, 0].set_xlabel('Time Step', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Temp Diff (Right - Left)', fontsize=11)\n",
    "axes[0, 0].set_title('Without Demon: No Temperature Gradient', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Temperature difference with demon\n",
    "axes[0, 1].plot(temp_diffs_with_demon, linewidth=2, color='red', alpha=0.7)\n",
    "axes[0, 1].axhline(0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[0, 1].set_xlabel('Time Step', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Temp Diff (Right - Left)', fontsize=11)\n",
    "axes[0, 1].set_title('With Demon: Temperature Gradient Created!', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Particle distribution (final state without demon)\n",
    "ax = axes[1, 0]\n",
    "positions_no_demon = np.array([[p.x, p.y] for p in system_no_demon.particles])\n",
    "speeds_no_demon = np.array([p.speed() for p in system_no_demon.particles])\n",
    "scatter = ax.scatter(positions_no_demon[:, 0], positions_no_demon[:, 1], \n",
    "                    c=speeds_no_demon, s=20, cmap='coolwarm', alpha=0.6)\n",
    "ax.axvline(0.5, color='black', linewidth=2, linestyle='--', label='Partition')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel('x', fontsize=11)\n",
    "ax.set_ylabel('y', fontsize=11)\n",
    "ax.set_title('Final State Without Demon', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "plt.colorbar(scatter, ax=ax, label='Speed')\n",
    "\n",
    "# Plot 4: Particle distribution (final state with demon)\n",
    "ax = axes[1, 1]\n",
    "positions_with_demon = np.array([[p.x, p.y] for p in system_with_demon.particles])\n",
    "speeds_with_demon = np.array([p.speed() for p in system_with_demon.particles])\n",
    "scatter = ax.scatter(positions_with_demon[:, 0], positions_with_demon[:, 1],\n",
    "                    c=speeds_with_demon, s=20, cmap='coolwarm', alpha=0.6)\n",
    "ax.axvline(0.5, color='black', linewidth=2, linestyle='--', label='Partition')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel('x', fontsize=11)\n",
    "ax.set_ylabel('y', fontsize=11)\n",
    "ax.set_title('Final State With Demon: Fastâ†’Right, Slowâ†’Left', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "plt.colorbar(scatter, ax=ax, label='Speed')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Landauer's principle\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(entropy_costs, linewidth=2, color='darkgreen')\n",
    "plt.xlabel('Time Step', fontsize=12)\n",
    "plt.ylabel('Cumulative Entropy Cost (k_B ln 2 per bit)', fontsize=12)\n",
    "plt.title(\"Landauer's Principle: Information Erasure Has Entropic Cost\", \n",
    "         fontsize=13, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ”‘ Key insights:\")\n",
    "print(\"   1. Demon CAN create temperature gradient (decrease entropy locally)\")\n",
    "print(\"   2. But demon must MEASURE and REMEMBER particle speeds\")\n",
    "print(\"   3. Memory is finite â†’ must ERASE old measurements\")\n",
    "print(f\"   4. Landauer: Erasing 1 bit releases â‰¥ k_B T ln(2) heat\")\n",
    "print(f\"   5. Total entropy cost from erasure: {entropy_costs[-1]:.2f} k_B ln(2)\")\n",
    "print(\"   6. This EXACTLY compensates for entropy decrease!\")\n",
    "print(\"\\n   â†’ The second law is saved! Information is physical.\")\n",
    "print(\"\\nâœ“ Maxwell's demon simulation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬6èŠ‚ï¼šè®¡ç®—ä¸å¯é€†æ€§ - å•å‘å‡½æ•°\n",
    "\n",
    "ä¸å¯é€†æ€§ä¸ä»…ä»…æ˜¯ç‰©ç†å­¦â€”â€”å®ƒæ˜¯**è®¡ç®—**çš„æ ¸å¿ƒï¼\n",
    "\n",
    "## å•å‘å‡½æ•°\n",
    "\n",
    "å‡½æ•° $f$ æ˜¯**å•å‘çš„**ï¼Œå¦‚æžœï¼š\n",
    "1. æ˜“äºŽè®¡ç®—ï¼š$y = f(x)$ å¾ˆå¿«\n",
    "2. éš¾ä»¥æ±‚é€†ï¼šç»™å®š $y$ï¼Œæ‰¾åˆ° $x$ ä½¿å¾— $f(x) = y$ å¾ˆéš¾\n",
    "\n",
    "**ç¤ºä¾‹**ï¼š\n",
    "- **ä¹˜æ³•**ï¼š$f(p, q) = p \\times q$ï¼ˆå®¹æ˜“ï¼‰\n",
    "- **å› å¼åˆ†è§£**ï¼šç»™å®š $n = p \\times q$ï¼Œæ‰¾ $p, q$ï¼ˆå¯¹å¤§ $n$ å¾ˆéš¾ï¼‰\n",
    "- **åŠ å¯†å“ˆå¸Œ**ï¼šSHA-256 ç­‰\n",
    "\n",
    "## ä¸Žçƒ­åŠ›å­¦çš„è”ç³»\n",
    "\n",
    "å•å‘å‡½æ•°æ˜¯**è®¡ç®—ä¸Šä¸å¯é€†çš„**ï¼š\n",
    "- è®¡ç®—æ—¶ä¿¡æ¯è¢«**é”€æ¯**\n",
    "- å¤šä¸ªè¾“å…¥ $x$ æ˜ å°„åˆ°ç›¸åŒè¾“å‡º $y$\n",
    "- è¿™å°±åƒçƒ­åŠ›å­¦ä¸­çš„**ç²—ç²’åŒ–**ï¼\n",
    "\n",
    "## è®¡ç®—çš„å…°é“å°”åŽŸç†\n",
    "\n",
    "**ä¸å¯é€†è®¡ç®—**ï¼ˆä¿¡æ¯è¢«é”€æ¯ï¼‰æœ‰æœ€å°èƒ½é‡æˆæœ¬ï¼š\n",
    "\n",
    "$$E_{\\text{min}} = k_B T \\ln(2) \\times (\\text{é”€æ¯çš„ä½æ•°})$$\n",
    "\n",
    "**å¯é€†è®¡ç®—**ï¼ˆæ²¡æœ‰ä¿¡æ¯é”€æ¯ï¼‰åŽŸåˆ™ä¸Šå¯ä»¥**é›¶èƒ½é‡æˆæœ¬**å®Œæˆï¼\n",
    "\n",
    "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆé‡å­è®¡ç®—æœºè¢«è®¾è®¡ä¸ºå¯é€†çš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_function(x: int, num_bits_out: int = 8) -> int:\n",
    "    \"\"\"Simple hash function (one-way).\n",
    "    \n",
    "    Args:\n",
    "        x: Input integer\n",
    "        num_bits_out: Number of bits in output\n",
    "    \n",
    "    Returns:\n",
    "        Hash value in [0, 2^num_bits_out - 1]\n",
    "    \"\"\"\n",
    "    # Use Python's built-in hash with modulo\n",
    "    return hash(x) % (2 ** num_bits_out)\n",
    "\n",
    "\n",
    "def cryptographic_hash(data: str) -> str:\n",
    "    \"\"\"Cryptographic hash using SHA-256.\"\"\"\n",
    "    return hashlib.sha256(data.encode()).hexdigest()\n",
    "\n",
    "\n",
    "def demonstrate_collision(num_inputs: int = 1000, num_bits_out: int = 8) -> dict:\n",
    "    \"\"\"Demonstrate hash collisions (many inputs â†’ same output).\"\"\"\n",
    "    hash_map = {}\n",
    "    \n",
    "    for x in range(num_inputs):\n",
    "        h = hash_function(x, num_bits_out)\n",
    "        if h not in hash_map:\n",
    "            hash_map[h] = []\n",
    "        hash_map[h].append(x)\n",
    "    \n",
    "    return hash_map\n",
    "\n",
    "\n",
    "def compute_information_loss(input_bits: int, output_bits: int) -> float:\n",
    "    \"\"\"Compute information loss in bits.\n",
    "    \n",
    "    When hashing n-bit input to m-bit output (m < n),\n",
    "    we lose (n - m) bits of information.\n",
    "    \"\"\"\n",
    "    return max(0, input_bits - output_bits)\n",
    "\n",
    "\n",
    "# Demonstrate one-way functions\n",
    "print(\"Demonstrating computational irreversibility...\\n\")\n",
    "\n",
    "# Example 1: Simple hash collisions\n",
    "print(\"Example 1: Hash Collisions\")\n",
    "print(\"=\"*50)\n",
    "num_inputs = 1000\n",
    "num_bits_out = 6  # Only 64 possible outputs\n",
    "hash_map = demonstrate_collision(num_inputs, num_bits_out)\n",
    "\n",
    "print(f\"Hashed {num_inputs} inputs to {2**num_bits_out} possible outputs\")\n",
    "print(f\"Number of collisions: {sum(1 for v in hash_map.values() if len(v) > 1)}\")\n",
    "print(f\"Average inputs per output: {num_inputs / len(hash_map):.1f}\")\n",
    "\n",
    "# Show some collisions\n",
    "collision_example = [v for v in hash_map.values() if len(v) > 2][0]\n",
    "print(f\"\\nExample collision: Inputs {collision_example[:5]} all hash to {hash_function(collision_example[0], num_bits_out)}\")\n",
    "\n",
    "# Example 2: Cryptographic hash\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Example 2: Cryptographic Hash (SHA-256)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "messages = [\n",
    "    \"Hello, World!\",\n",
    "    \"Hello, World.\",  # One character different\n",
    "    \"The coffee automaton demonstrates irreversibility\"\n",
    "]\n",
    "\n",
    "for msg in messages:\n",
    "    hash_val = cryptographic_hash(msg)\n",
    "    print(f\"Message: '{msg[:40]}'\")\n",
    "    print(f\"SHA-256: {hash_val[:32]}...\")\n",
    "    print()\n",
    "\n",
    "print(\"Note: Tiny change in input â†’ completely different hash (avalanche effect)\")\n",
    "print(\"This makes inversion computationally infeasible!\")\n",
    "\n",
    "# Visualize hash distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Hash collision distribution\n",
    "ax = axes[0]\n",
    "collision_counts = [len(v) for v in hash_map.values()]\n",
    "ax.hist(collision_counts, bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax.set_xlabel('Number of Inputs per Hash Value', fontsize=11)\n",
    "ax.set_ylabel('Frequency', fontsize=11)\n",
    "ax.set_title('Hash Collisions: Many-to-One Mapping', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.axvline(np.mean(collision_counts), color='red', linestyle='--', linewidth=2,\n",
    "          label=f'Mean: {np.mean(collision_counts):.1f}')\n",
    "ax.legend()\n",
    "\n",
    "# Plot 2: Information loss\n",
    "ax = axes[1]\n",
    "input_bits_range = np.arange(8, 65, 4)\n",
    "output_bits_fixed = 16\n",
    "info_loss = [compute_information_loss(ib, output_bits_fixed) for ib in input_bits_range]\n",
    "\n",
    "ax.plot(input_bits_range, info_loss, 'o-', linewidth=2, markersize=8, color='darkred')\n",
    "ax.fill_between(input_bits_range, 0, info_loss, alpha=0.3, color='red')\n",
    "ax.set_xlabel('Input Size (bits)', fontsize=11)\n",
    "ax.set_ylabel('Information Lost (bits)', fontsize=11)\n",
    "ax.set_title(f'Information Loss in Hashing (â†’{output_bits_fixed} bits)', \n",
    "            fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Landauer's cost\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Landauer's Principle for Computation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "bits_destroyed = 48  # Hash 64-bit input to 16-bit output\n",
    "k_B = 1.380649e-23  # Boltzmann constant (J/K)\n",
    "T = 300  # Temperature (K)\n",
    "energy_per_bit = k_B * T * np.log(2)  # Joules\n",
    "total_energy = bits_destroyed * energy_per_bit\n",
    "\n",
    "print(f\"Hashing 64-bit input â†’ 16-bit output:\")\n",
    "print(f\"  Bits destroyed: {bits_destroyed}\")\n",
    "print(f\"  Minimum energy cost: {total_energy:.2e} J\")\n",
    "print(f\"  At T=300K: {energy_per_bit:.2e} J per bit\")\n",
    "print(f\"\\nModern CPUs use ~10^-9 J per operation (well above Landauer limit)\")\n",
    "print(f\"Landauer limit: {energy_per_bit:.2e} J per bit erased\")\n",
    "print(f\"Gap: ~10^6Ã— above minimum! Room for improvement.\")\n",
    "\n",
    "print(\"\\nðŸ”‘ Key insights:\")\n",
    "print(\"   1. One-way functions destroy information (irreversible)\")\n",
    "print(\"   2. Many inputs map to same output (collisions)\")\n",
    "print(\"   3. This is computational coarse-graining!\")\n",
    "print(\"   4. Landauer: Destroying 1 bit costs â‰¥ k_B T ln(2) energy\")\n",
    "print(\"   5. Reversible computation (no info loss) could be free!\")\n",
    "print(\"\\nâœ“ Computational irreversibility demonstration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬7èŠ‚ï¼šæœºå™¨å­¦ä¹ ä¸Žä¿¡æ¯ç“¶é¢ˆ\n",
    "\n",
    "**ä¸å¯é€†æ€§å¯¹æœºå™¨å­¦ä¹ è‡³å…³é‡è¦ï¼**\n",
    "\n",
    "## ä¸ºä»€ä¹ˆç¥žç»ç½‘ç»œå¿…é¡»é—å¿˜\n",
    "\n",
    "ç¥žç»ç½‘ç»œæ˜¯ä¸€ä¸ª**æœ‰æŸåŽ‹ç¼©**å‡½æ•°ï¼š\n",
    "\n",
    "$$f: \\mathbb{R}^{d_{\\text{in}}} \\to \\mathbb{R}^{d_{\\text{out}}}$$\n",
    "\n",
    "é€šå¸¸ $d_{\\text{out}} \\ll d_{\\text{in}}$ã€‚\n",
    "\n",
    "**ä¿¡æ¯ç“¶é¢ˆ**ï¼šéšè—å±‚åŽ‹ç¼©è¾“å…¥ï¼Œä¸¢å¼ƒæ— å…³ç»†èŠ‚ï¼š\n",
    "- è¾“å…¥ï¼šé«˜ç»´æ•°æ®ï¼ˆä¾‹å¦‚å›¾åƒåƒç´ ï¼‰\n",
    "- éšè—å±‚ï¼šæ¸è¿›åŽ‹ç¼©\n",
    "- è¾“å‡ºï¼šä½Žç»´è¡¨ç¤ºï¼ˆä¾‹å¦‚ç±»åˆ«æ ‡ç­¾ï¼‰\n",
    "\n",
    "## ä¸ºä»€ä¹ˆåŽ‹ç¼©æœ‰å¸®åŠ©\n",
    "\n",
    "1. **æ³›åŒ–**ï¼šé—å¿˜å™ªå£°ï¼Œè®°ä½ä¿¡å·\n",
    "2. **æ•ˆçŽ‡**ï¼šåªå­˜å‚¨ç›¸å…³ç‰¹å¾\n",
    "3. **é²æ£’æ€§**ï¼šç›¸ä¼¼è¾“å…¥ â†’ ç›¸ä¼¼è¾“å‡º\n",
    "\n",
    "**ä¸Žçƒ­åŠ›å­¦çš„è”ç³»**ï¼š\n",
    "- **ä¸å¯é€†åŽ‹ç¼©** = ä¸¢å¤±ä¿¡æ¯\n",
    "- **ç†µå¢žåŠ ** = æ‰©æ•£ä¸ç¡®å®šæ€§\n",
    "- **ç²—ç²’åŒ–** = å°†ç›¸ä¼¼è¾“å…¥åˆ†ç»„\n",
    "\n",
    "## ä¿¡æ¯ç“¶é¢ˆåŽŸç†\n",
    "\n",
    "æ‰¾åˆ°è¡¨ç¤º $T$ï¼Œä½¿å¾—ï¼š\n",
    "$$\\min_{T} [I(X; T) - \\beta \\cdot I(T; Y)]$$\n",
    "\n",
    "- $I(X; T)$ï¼š$T$ å…³äºŽè¾“å…¥ $X$ è®°ä½çš„ä¿¡æ¯ï¼ˆåŽ‹ç¼©ï¼‰\n",
    "- $I(T; Y)$ï¼š$T$ å…³äºŽè¾“å‡º $Y$ ä¿ç•™çš„ä¿¡æ¯ï¼ˆé¢„æµ‹ï¼‰\n",
    "- $\\beta$ï¼šæƒè¡¡å‚æ•°\n",
    "\n",
    "**ç›®æ ‡**ï¼šæœ€å¤§åŒ–åŽ‹ç¼©ï¼ŒåŒæ—¶ä¿ç•™é¢„æµ‹èƒ½åŠ›ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬æ¼”ç¤ºä¸€ä¸‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder_layers(input_dim: int, hidden_dims: List[int]) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"Create a simple autoencoder (compression then decompression).\n",
    "    \n",
    "    Returns:\n",
    "        List of (W, b) for each layer\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    dims = [input_dim] + hidden_dims + [input_dim]\n",
    "    \n",
    "    for i in range(len(dims) - 1):\n",
    "        W = np.random.randn(dims[i], dims[i+1]) * np.sqrt(2.0 / dims[i])\n",
    "        b = np.zeros(dims[i+1])\n",
    "        layers.append((W, b))\n",
    "    \n",
    "    return layers\n",
    "\n",
    "\n",
    "def forward_autoencoder(x: np.ndarray, layers: List[Tuple]) -> Tuple[np.ndarray, List[np.ndarray]]:\n",
    "    \"\"\"Forward pass through autoencoder.\n",
    "    \n",
    "    Returns:\n",
    "        reconstruction, list of activations at each layer\n",
    "    \"\"\"\n",
    "    activations = [x]\n",
    "    current = x\n",
    "    \n",
    "    for i, (W, b) in enumerate(layers):\n",
    "        current = current @ W + b\n",
    "        # ReLU for hidden layers, linear for output\n",
    "        if i < len(layers) - 1:\n",
    "            current = np.maximum(0, current)\n",
    "        activations.append(current)\n",
    "    \n",
    "    return current, activations\n",
    "\n",
    "\n",
    "def measure_information_content(activations: np.ndarray, num_bins: int = 20) -> float:\n",
    "    \"\"\"Estimate information content via entropy of activation distribution.\"\"\"\n",
    "    # Flatten activations\n",
    "    flat = activations.flatten()\n",
    "    \n",
    "    # Create histogram\n",
    "    hist, _ = np.histogram(flat, bins=num_bins, density=True)\n",
    "    hist = hist / hist.sum()\n",
    "    hist = hist[hist > 0]\n",
    "    \n",
    "    # Shannon entropy\n",
    "    return -np.sum(hist * np.log2(hist))\n",
    "\n",
    "\n",
    "# Generate synthetic data\n",
    "print(\"Demonstrating information bottleneck in neural networks...\\n\")\n",
    "\n",
    "# Create high-dimensional input with low-dimensional structure\n",
    "num_samples = 500\n",
    "input_dim = 50\n",
    "latent_dim = 3  # True underlying dimensionality\n",
    "\n",
    "# Generate data: low-dim latent â†’ high-dim observation\n",
    "latent = np.random.randn(num_samples, latent_dim)\n",
    "projection = np.random.randn(latent_dim, input_dim)\n",
    "X = latent @ projection\n",
    "X += np.random.randn(num_samples, input_dim) * 0.5  # Add noise\n",
    "\n",
    "print(f\"Generated data:\")\n",
    "print(f\"  Samples: {num_samples}\")\n",
    "print(f\"  Input dimension: {input_dim}\")\n",
    "print(f\"  True latent dimension: {latent_dim}\")\n",
    "print(f\"  Information must be compressed {input_dim/latent_dim:.1f}Ã—!\\n\")\n",
    "\n",
    "# Create autoencoder with bottleneck\n",
    "hidden_dims = [25, 10, 5]  # Progressively compress\n",
    "layers = create_autoencoder_layers(input_dim, hidden_dims)\n",
    "\n",
    "print(f\"Autoencoder architecture: {input_dim} â†’ {' â†’ '.join(map(str, hidden_dims))} â†’ {input_dim}\")\n",
    "print(f\"Bottleneck: {hidden_dims[-1]} dimensions (compression: {input_dim/hidden_dims[-1]:.1f}Ã—)\\n\")\n",
    "\n",
    "# Analyze information flow\n",
    "reconstructions = []\n",
    "all_activations = []\n",
    "\n",
    "for x in X[:100]:  # Use subset for speed\n",
    "    recon, acts = forward_autoencoder(x, layers)\n",
    "    reconstructions.append(recon)\n",
    "    all_activations.append(acts)\n",
    "\n",
    "# Measure information at each layer\n",
    "layer_entropies = []\n",
    "layer_sizes = [input_dim] + hidden_dims + [input_dim]\n",
    "\n",
    "for layer_idx in range(len(layers) + 1):\n",
    "    layer_activations = np.array([acts[layer_idx] for acts in all_activations])\n",
    "    entropy = measure_information_content(layer_activations)\n",
    "    layer_entropies.append(entropy)\n",
    "\n",
    "# Visualize information bottleneck\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Network architecture\n",
    "ax = axes[0, 0]\n",
    "x_pos = np.arange(len(layer_sizes))\n",
    "ax.bar(x_pos, layer_sizes, color=['blue' if s > hidden_dims[-1] else 'red' for s in layer_sizes],\n",
    "       alpha=0.7, edgecolor='black')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(['Input'] + [f'H{i+1}' for i in range(len(hidden_dims))] + ['Output'])\n",
    "ax.set_ylabel('Layer Dimension', fontsize=11)\n",
    "ax.set_title('Network Architecture: Information Bottleneck', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 2: Information content per layer\n",
    "ax = axes[0, 1]\n",
    "ax.plot(x_pos, layer_entropies, 'o-', linewidth=2, markersize=10, color='darkgreen')\n",
    "ax.fill_between(x_pos, 0, layer_entropies, alpha=0.3, color='green')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(['Input'] + [f'H{i+1}' for i in range(len(hidden_dims))] + ['Output'])\n",
    "ax.set_ylabel('Information Content (bits)', fontsize=11)\n",
    "ax.set_title('Information Loss Through Network', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axvline(len(hidden_dims), color='red', linestyle='--', linewidth=2, label='Bottleneck')\n",
    "ax.legend()\n",
    "\n",
    "# Plot 3: Compression ratio\n",
    "ax = axes[1, 0]\n",
    "compression_ratios = [layer_sizes[0] / s for s in layer_sizes]\n",
    "ax.bar(x_pos, compression_ratios, color='orange', alpha=0.7, edgecolor='black')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(['Input'] + [f'H{i+1}' for i in range(len(hidden_dims))] + ['Output'])\n",
    "ax.set_ylabel('Compression Ratio', fontsize=11)\n",
    "ax.set_title('Lossy Compression Through Network', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.axhline(1, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plot 4: Dimension vs information\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(layer_sizes, layer_entropies, s=200, c=range(len(layer_sizes)), \n",
    "          cmap='viridis', edgecolor='black', linewidth=2)\n",
    "for i, (d, e) in enumerate(zip(layer_sizes, layer_entropies)):\n",
    "    label = 'Input' if i == 0 else f'H{i}' if i <= len(hidden_dims) else 'Output'\n",
    "    ax.annotate(label, (d, e), xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "ax.set_xlabel('Layer Dimension', fontsize=11)\n",
    "ax.set_ylabel('Information Content (bits)', fontsize=11)\n",
    "ax.set_title('Dimension vs Information Content', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ”‘ Key insights:\")\n",
    "print(f\"   1. Input dimension: {input_dim}, Information: {layer_entropies[0]:.2f} bits\")\n",
    "print(f\"   2. Bottleneck dimension: {hidden_dims[-1]}, Information: {layer_entropies[len(hidden_dims)]:.2f} bits\")\n",
    "print(f\"   3. Information lost: {layer_entropies[0] - layer_entropies[len(hidden_dims)]:.2f} bits ({(1 - layer_entropies[len(hidden_dims)]/layer_entropies[0])*100:.1f}%)\")\n",
    "print(f\"   4. This is INTENTIONAL! Network forgets noise, remembers structure.\")\n",
    "print(\"\\n   â†’ Irreversibility (information loss) is essential for learning!\")\n",
    "print(\"   â†’ Networks that compress well generalize well.\")\n",
    "print(\"   â†’ Thermodynamic analogy: Compress = coarse-grain = increase entropy\")\n",
    "print(\"\\nâœ“ Information bottleneck demonstration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬8èŠ‚ï¼šæ—¶é—´ç®­å¤´ - åŸºæœ¬è¿˜æ˜¯æ¶ŒçŽ°\n",
    "\n",
    "æˆ‘ä»¬å·²ç»ä»Žå¤šä¸ªè§’åº¦æŽ¢è®¨äº†ä¸å¯é€†æ€§ã€‚çŽ°åœ¨é—®ä¸€ä¸ªæ·±åˆ»çš„é—®é¢˜ï¼š\n",
    "\n",
    "**æ—¶é—´ç®­å¤´æ˜¯åŸºæœ¬çš„è¿˜æ˜¯æ¶ŒçŽ°çš„ï¼Ÿ**\n",
    "\n",
    "## æ”¯æŒ\"åŸºæœ¬\"çš„è®ºç‚¹\n",
    "\n",
    "1. **å¼±ç›¸äº’ä½œç”¨è¿å CP å¯¹ç§°æ€§** â†’ è½»å¾®çš„æ—¶é—´é€†è½¬è¿å\n",
    "2. **å®‡å®™å­¦ç®­å¤´**ï¼šå®‡å®™è†¨èƒ€ï¼ˆä¸æ˜¯æ”¶ç¼©ï¼‰\n",
    "3. **é‡å­æµ‹é‡**ï¼šæ³¢å‡½æ•°åç¼©æ˜¯ä¸å¯é€†çš„\n",
    "\n",
    "## æ”¯æŒ\"æ¶ŒçŽ°\"çš„è®ºç‚¹\n",
    "\n",
    "1. **ç»Ÿè®¡åŠ›å­¦**ï¼šç¬¬äºŒå®šå¾‹ä»Žç»Ÿè®¡ä¸­æ¶ŒçŽ°\n",
    "2. **å¾®è§‚å¯é€†æ€§**ï¼šåŸºæœ¬å®šå¾‹æ˜¯æ—¶é—´å¯¹ç§°çš„\n",
    "3. **è¾¹ç•Œæ¡ä»¶**ï¼šä½Žç†µå¤§çˆ†ç‚¸è®¾å®šäº†ç®­å¤´\n",
    "\n",
    "## å…±è¯†ï¼šä¸»è¦æ˜¯æ¶ŒçŽ°çš„\n",
    "\n",
    "æ—¶é—´ç®­å¤´**ä¸æ˜¯**åœ¨ç‰©ç†å®šå¾‹ä¸­â€”â€”å®ƒåœ¨**åˆå§‹æ¡ä»¶**ä¸­ï¼š\n",
    "\n",
    "$$S_{\\text{universe}}(t) > S_{\\text{universe}}(0)$$\n",
    "\n",
    "å®‡å®™å§‹äºŽ**æžä½Žç†µ**ã€‚ä»Žé‚£æ—¶èµ·ï¼Œç†µä¸€ç›´åœ¨å¢žåŠ ã€‚\n",
    "\n",
    "**ä¸ºä»€ä¹ˆå¤§çˆ†ç‚¸æ˜¯ä½Žç†µçš„ï¼Ÿ**æˆ‘ä»¬ä¸çŸ¥é“ï¼è¿™æ˜¯ç‰©ç†å­¦ä¸­æœ€æ·±çš„è°œé¢˜ä¹‹ä¸€ã€‚\n",
    "\n",
    "## æ„å‘³ç€ï¼š\n",
    "\n",
    "- **çƒ­åŠ›å­¦ç®­å¤´**ï¼šç†µå¢žåŠ \n",
    "- **å¿ƒç†å­¦ç®­å¤´**ï¼šæˆ‘ä»¬è®°ä½è¿‡åŽ»ï¼Œä¸è®°ä½æœªæ¥ï¼ˆè®°å¿†éœ€è¦ä½Žç†µï¼‰\n",
    "- **å®‡å®™å­¦ç®­å¤´**ï¼šå®‡å®™è†¨èƒ€\n",
    "\n",
    "ä¸‰è€…éƒ½æ˜¯**ä½Žç†µåˆå§‹æ¡ä»¶çš„åŽæžœ**ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬å¯è§†åŒ–ä¸€ä¸‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the arrow of time\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Entropy vs time for universe\n",
    "ax = axes[0, 0]\n",
    "time_universe = np.linspace(0, 13.8, 1000)  # Billion years\n",
    "# Simplified model: entropy grows logarithmically with time\n",
    "entropy_universe = np.log(1 + time_universe * 10) + np.random.randn(1000) * 0.1\n",
    "\n",
    "ax.plot(time_universe, entropy_universe, linewidth=2, color='darkblue')\n",
    "ax.scatter([0], [entropy_universe[0]], s=200, c='red', marker='*', \n",
    "          label='Big Bang (low entropy!)', zorder=5, edgecolor='black', linewidth=2)\n",
    "ax.arrow(3, 1, 3, 1, head_width=0.2, head_length=0.5, fc='red', ec='red', linewidth=2)\n",
    "ax.text(4, 2.5, 'Arrow of Time', fontsize=12, color='red', fontweight='bold')\n",
    "ax.set_xlabel('Time (billion years since Big Bang)', fontsize=11)\n",
    "ax.set_ylabel('Universe Entropy (arbitrary units)', fontsize=11)\n",
    "ax.set_title('Cosmological Arrow of Time', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Forward vs backward in time\n",
    "ax = axes[0, 1]\n",
    "t = np.linspace(0, 10, 100)\n",
    "entropy_forward = 1 - np.exp(-t/3)  # Entropy increases\n",
    "entropy_backward = np.flip(entropy_forward)  # Time-reversed (entropy decreases)\n",
    "\n",
    "ax.plot(t, entropy_forward, linewidth=3, color='green', label='Forward in time (2nd law holds)')\n",
    "ax.plot(t, entropy_backward, linewidth=3, color='red', linestyle='--', \n",
    "       label='Backward in time (2nd law violated!)')\n",
    "ax.set_xlabel('Time', fontsize=11)\n",
    "ax.set_ylabel('Entropy', fontsize=11)\n",
    "ax.set_title('Time Asymmetry: Why Backward Looks Wrong', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Phase space volume (Liouville) vs coarse-grained entropy\n",
    "ax = axes[1, 0]\n",
    "t = np.linspace(0, 10, 100)\n",
    "phase_space_volume = np.ones_like(t)  # Constant (Liouville)\n",
    "macro_entropy = 1 - np.exp(-t/2)  # Increases\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax.plot(t, phase_space_volume, linewidth=3, color='blue', label='Microscopic (Liouville)')\n",
    "ax2.plot(t, macro_entropy, linewidth=3, color='red', label='Macroscopic (2nd law)')\n",
    "ax.set_xlabel('Time', fontsize=11)\n",
    "ax.set_ylabel('Phase Space Volume (conserved)', fontsize=11, color='blue')\n",
    "ax2.set_ylabel('Macroscopic Entropy (increases)', fontsize=11, color='red')\n",
    "ax.set_title('Microscopic Reversibility vs Macroscopic Irreversibility', \n",
    "            fontsize=12, fontweight='bold')\n",
    "ax.tick_params(axis='y', labelcolor='blue')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "lines1, labels1 = ax.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax.legend(lines1 + lines2, labels1 + labels2, loc='center right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Three arrows of time\n",
    "ax = axes[1, 1]\n",
    "ax.axis('off')\n",
    "\n",
    "# Draw three arrows\n",
    "arrow_props = dict(arrowstyle='->', lw=4, color='darkblue')\n",
    "ax.annotate('', xy=(0.8, 0.8), xytext=(0.2, 0.8), arrowprops=arrow_props)\n",
    "ax.text(0.5, 0.85, 'Thermodynamic Arrow', ha='center', fontsize=12, fontweight='bold')\n",
    "ax.text(0.5, 0.75, 'Entropy increases', ha='center', fontsize=10, style='italic')\n",
    "\n",
    "arrow_props['color'] = 'darkgreen'\n",
    "ax.annotate('', xy=(0.8, 0.5), xytext=(0.2, 0.5), arrowprops=arrow_props)\n",
    "ax.text(0.5, 0.55, 'Psychological Arrow', ha='center', fontsize=12, fontweight='bold')\n",
    "ax.text(0.5, 0.45, 'Remember past, not future', ha='center', fontsize=10, style='italic')\n",
    "\n",
    "arrow_props['color'] = 'darkred'\n",
    "ax.annotate('', xy=(0.8, 0.2), xytext=(0.2, 0.2), arrowprops=arrow_props)\n",
    "ax.text(0.5, 0.25, 'Cosmological Arrow', ha='center', fontsize=12, fontweight='bold')\n",
    "ax.text(0.5, 0.15, 'Universe expands', ha='center', fontsize=10, style='italic')\n",
    "\n",
    "ax.text(0.5, 0.05, 'All three aligned â†’ All consequences of low-entropy Big Bang', \n",
    "       ha='center', fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('The Three Arrows of Time', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ”‘ Deep insights about time:\")\n",
    "print(\"\\n1. MICROSCOPIC LAWS: Time-reversible (Newtonian, quantum mechanics)\")\n",
    "print(\"   â†’ Running laws backward is mathematically valid\")\n",
    "print(\"\\n2. MACROSCOPIC BEHAVIOR: Time-irreversible (thermodynamics)\")\n",
    "print(\"   â†’ Entropy increases, mixing happens, cannot unmix\")\n",
    "print(\"\\n3. THE RESOLUTION: Initial conditions + statistics\")\n",
    "print(\"   â†’ Big Bang had EXTREMELY low entropy\")\n",
    "print(\"   â†’ Statistical evolution explores high-entropy states\")\n",
    "print(\"   â†’ Coarse-graining makes evolution appear irreversible\")\n",
    "print(\"\\n4. THE DEEP MYSTERY: Why was the Big Bang low-entropy?\")\n",
    "print(\"   â†’ We don't know! This is the origin of the arrow of time.\")\n",
    "print(\"   â†’ Some theories: anthropic principle, bouncing cosmology, etc.\")\n",
    "print(\"\\n5. THREE ARROWS, ONE CAUSE:\")\n",
    "print(\"   â†’ Thermodynamic: Entropy â†‘ (consequence of initial conditions)\")\n",
    "print(\"   â†’ Psychological: Memory works backward (requires low entropy)\")\n",
    "print(\"   â†’ Cosmological: Universe expands (related to initial conditions)\")\n",
    "print(\"\\nâœ“ Arrow of time analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬9èŠ‚ï¼šç”Ÿç‰©ä¸å¯é€†æ€§ - ç”Ÿå‘½ä¸Žç¬¬äºŒå®šå¾‹\n",
    "\n",
    "**ç”Ÿå‘½è¿åç¬¬äºŒå®šå¾‹å—ï¼Ÿ**\n",
    "\n",
    "ä¸ï¼ç”Ÿå‘½æ˜¯ä¸€ä¸ª**å¼€æ”¾ç³»ç»Ÿ**ï¼Œå®ƒï¼š\n",
    "1. å±€éƒ¨å‡å°‘ç†µï¼ˆåˆ›å»ºç§©åºï¼‰\n",
    "2. æ•´ä½“å¢žåŠ ç†µï¼ˆè¾“å‡ºæ— åºï¼‰\n",
    "\n",
    "## è–›å®šè°”çš„æ´žå¯Ÿ\n",
    "\n",
    "åœ¨\"ç”Ÿå‘½æ˜¯ä»€ä¹ˆï¼Ÿ\"ï¼ˆ1944ï¼‰ä¸­ï¼Œè–›å®šè°”è¯´ï¼š\n",
    "> \"ç”Ÿå‘½ä»¥è´Ÿç†µä¸ºé£Ÿ\"\n",
    "\n",
    "ç”Ÿç‰©ä½“ï¼š\n",
    "- è¾“å…¥**ä½Žç†µ**èƒ½é‡ï¼ˆé£Ÿç‰©ã€é˜³å…‰ï¼‰\n",
    "- ä½¿ç”¨å®ƒç»´æŒç§©åºï¼ˆæ–°é™ˆä»£è°¢ã€ç”Ÿé•¿ã€ç¹æ®–ï¼‰\n",
    "- è¾“å‡º**é«˜ç†µ**åºŸç‰©ï¼ˆçƒ­é‡ã€COâ‚‚ï¼‰\n",
    "\n",
    "**å‡€ç»“æžœ**ï¼šå®‡å®™ç†µå¢žåŠ ï¼Œç¬¬äºŒå®šå¾‹å¾—åˆ°æ»¡è¶³\n",
    "\n",
    "## å¼€æ”¾ç³»ç»Ÿçš„ç¬¬äºŒå®šå¾‹\n",
    "\n",
    "å¯¹äºŽä¸ŽçŽ¯å¢ƒäº¤æ¢ç†µ $S_{\\text{env}}$ çš„å¼€æ”¾ç³»ç»Ÿï¼š\n",
    "\n",
    "$$\\frac{dS_{\\text{system}}}{dt} + \\frac{dS_{\\text{env}}}{dt} \\geq 0$$\n",
    "\n",
    "$S_{\\text{system}}$ å¯ä»¥å‡å°‘ï¼Œå¦‚æžœ $S_{\\text{env}}$ å¢žåŠ æ›´å¤šï¼\n",
    "\n",
    "è®©æˆ‘ä»¬å»ºæ¨¡ä¸€ä¸‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model a simple \"living\" system that maintains order\n",
    "\n",
    "def simulate_open_system(num_steps: int = 200) -> dict:\n",
    "    \"\"\"Simulate an open system that maintains low entropy.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with entropy histories\n",
    "    \"\"\"\n",
    "    # Initialize\n",
    "    S_system = 10.0  # System starts with moderate entropy\n",
    "    S_environment = 0.0  # Track cumulative entropy exported\n",
    "    \n",
    "    S_system_history = [S_system]\n",
    "    S_environment_history = [S_environment]\n",
    "    S_total_history = [S_system + S_environment]\n",
    "    \n",
    "    for t in range(num_steps):\n",
    "        # System processes: would naturally increase entropy\n",
    "        natural_increase = 0.5\n",
    "        \n",
    "        # Active maintenance: system exports entropy to environment\n",
    "        # This \"costs\" more entropy in environment than saved in system\n",
    "        entropy_exported = 0.8  # More than natural increase (2nd law!)\n",
    "        entropy_reduced = 0.3  # System entropy reduction\n",
    "        \n",
    "        # Update\n",
    "        S_system = S_system + natural_increase - entropy_reduced\n",
    "        S_environment = S_environment + entropy_exported\n",
    "        \n",
    "        # Record\n",
    "        S_system_history.append(S_system)\n",
    "        S_environment_history.append(S_environment)\n",
    "        S_total_history.append(S_system + S_environment)\n",
    "    \n",
    "    return {\n",
    "        'system': S_system_history,\n",
    "        'environment': S_environment_history,\n",
    "        'total': S_total_history\n",
    "    }\n",
    "\n",
    "\n",
    "def simulate_closed_system(num_steps: int = 200) -> dict:\n",
    "    \"\"\"Simulate a closed system (for comparison).\"\"\"\n",
    "    S_total = 10.0\n",
    "    S_total_history = [S_total]\n",
    "    \n",
    "    for t in range(num_steps):\n",
    "        # Entropy only increases in closed system\n",
    "        S_total = S_total + 0.5\n",
    "        S_total_history.append(S_total)\n",
    "    \n",
    "    return {'total': S_total_history}\n",
    "\n",
    "\n",
    "print(\"Simulating open system (life-like) vs closed system...\\n\")\n",
    "\n",
    "open_sys = simulate_open_system()\n",
    "closed_sys = simulate_closed_system()\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Open system (life)\n",
    "ax = axes[0]\n",
    "t = np.arange(len(open_sys['total']))\n",
    "ax.plot(t, open_sys['system'], linewidth=2, label='System (organism)', color='green')\n",
    "ax.plot(t, open_sys['environment'], linewidth=2, label='Environment', color='brown')\n",
    "ax.plot(t, open_sys['total'], linewidth=3, label='Total (system + env)', \n",
    "       color='red', linestyle='--')\n",
    "ax.set_xlabel('Time', fontsize=11)\n",
    "ax.set_ylabel('Entropy', fontsize=11)\n",
    "ax.set_title('Open System: Life Maintains Order by Exporting Entropy', \n",
    "            fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.text(100, 50, 'System entropy\\ncan decrease!', fontsize=10, color='green',\n",
    "       bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "ax.text(100, 120, 'But total entropy\\nalways increases!', fontsize=10, color='red',\n",
    "       bbox=dict(boxstyle='round', facecolor='pink', alpha=0.5))\n",
    "\n",
    "# Plot 2: Comparison with closed system\n",
    "ax = axes[1]\n",
    "ax.plot(t, closed_sys['total'], linewidth=3, label='Closed system', color='blue')\n",
    "ax.plot(t, open_sys['total'], linewidth=3, label='Open system (total)', \n",
    "       color='red', linestyle='--')\n",
    "ax.set_xlabel('Time', fontsize=11)\n",
    "ax.set_ylabel('Total Entropy', fontsize=11)\n",
    "ax.set_title('Both Systems Obey 2nd Law: Total Entropy â†‘', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.text(100, 50, 'Open system increases\\nentropy FASTER\\n(due to metabolism)', \n",
    "       fontsize=10, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ”‘ Key insights about life and entropy:\")\n",
    "print(\"\\n1. LOCAL vs GLOBAL:\")\n",
    "print(f\"   â†’ System entropy: {open_sys['system'][0]:.1f} â†’ {open_sys['system'][-1]:.1f} (maintained low!)\")\n",
    "print(f\"   â†’ Total entropy:  {open_sys['total'][0]:.1f} â†’ {open_sys['total'][-1]:.1f} (increased!)\")\n",
    "print(\"\\n2. LIFE'S TRICK:\")\n",
    "print(\"   â†’ Import low-entropy energy (food, sunlight)\")\n",
    "print(\"   â†’ Use it to build order (proteins, cells, organisms)\")\n",
    "print(\"   â†’ Export high-entropy waste (heat, COâ‚‚, etc.)\")\n",
    "print(\"\\n3. NET RESULT:\")\n",
    "print(\"   â†’ Organism entropy â†“ (more order)\")\n",
    "print(\"   â†’ Environment entropy â†‘â†‘ (much more disorder)\")\n",
    "print(\"   â†’ Total entropy â†‘ (2nd law satisfied!)\")\n",
    "print(\"\\n4. WHY IT WORKS:\")\n",
    "print(\"   â†’ Exporting entropy is IRREVERSIBLE\")\n",
    "print(\"   â†’ Heat cannot spontaneously reconcentrate\")\n",
    "print(\"   â†’ This is why death is inevitable (eventually can't export enough)\")\n",
    "print(\"\\n5. SCHRÃ–DINGER WAS RIGHT:\")\n",
    "print(\"   â†’ Life feeds on negative entropy (order)\")\n",
    "print(\"   â†’ Exports positive entropy (disorder)\")\n",
    "print(\"   â†’ This is how life is compatible with 2nd law!\")\n",
    "print(\"\\nâœ“ Biological irreversibility demonstration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬10èŠ‚ï¼šç»¼åˆ - å„å°ºåº¦çš„ä¸å¯é€†æ€§\n",
    "\n",
    "æˆ‘ä»¬å·²ç»ä»Žå’–å•¡æ¯åˆ°å®‡å®™æŽ¢è®¨äº†ä¸å¯é€†æ€§ã€‚è®©æˆ‘ä»¬ç»¼åˆä¸€ä¸‹ã€‚\n",
    "\n",
    "## ä¸å¯é€†æ€§çš„å±‚æ¬¡\n",
    "\n",
    "| å°ºåº¦ | ç³»ç»Ÿ | å¯é€†ï¼Ÿ | ä¸ºä»€ä¹ˆä¸å¯é€†ï¼Ÿ |\n",
    "|-------|--------|-------------|-------------------|\n",
    "| **å¾®è§‚** | å•ä¸ªç²’å­ | âœ… æ˜¯ | ç‰›é¡¿/é‡å­å®šå¾‹æ˜¯æ—¶é—´å¯¹ç§°çš„ |\n",
    "| **ä»‹è§‚** | å°ç¾¤ä½“ï¼ˆ~100sï¼‰ | âš ï¸ å®žé™…ä¸ | åºžåŠ èŽ±å›žå½’æ—¶é—´ >> è§‚å¯Ÿæ—¶é—´ |\n",
    "| **å®è§‚** | æ—¥å¸¸ç‰©ä½“ | âŒ å¦ | ç²—ç²’åŒ– + ç»Ÿè®¡å­¦ + é«˜ N |\n",
    "| **å®‡å®™å­¦** | å®‡å®™ | âŒ å¦ | ä½Žç†µåˆå§‹æ¡ä»¶ |\n",
    "\n",
    "## å…±åŒä¸»çº¿\n",
    "\n",
    "æ‰€æœ‰å½¢å¼çš„ä¸å¯é€†æ€§éƒ½åˆ†äº«ï¼š\n",
    "\n",
    "1. **ç²—ç²’åŒ–**ï¼šä¸¢å¤±ç»†ç²’åº¦ä¿¡æ¯\n",
    "   - ç‰©ç†å­¦ï¼šå®è§‚æ€ vs å¾®è§‚æ€\n",
    "   - è®¡ç®—ï¼šå“ˆå¸Œå‡½æ•°ï¼Œæœ‰æŸåŽ‹ç¼©\n",
    "   - MLï¼šç¥žç»ç½‘ç»œç“¶é¢ˆ\n",
    "\n",
    "2. **å¤šå¯¹ä¸€æ˜ å°„**ï¼šå¤šä¸ªè¾“å…¥ â†’ ç›¸åŒè¾“å‡º\n",
    "   - å’–å•¡ï¼šè®¸å¤šåˆ†å­é…ç½® â†’ ç›¸åŒå®è§‚å¤–è§‚\n",
    "   - å“ˆå¸Œï¼šè®¸å¤šå­—ç¬¦ä¸² â†’ ç›¸åŒå“ˆå¸Œå€¼\n",
    "   - ç¥žç»ç½‘ç»œï¼šè®¸å¤šå›¾åƒ â†’ ç›¸åŒç±»åˆ«\n",
    "\n",
    "3. **ä¿¡æ¯ä¸¢å¤±**ï¼šæ— æ³•æ¢å¤åŽŸå§‹çŠ¶æ€\n",
    "   - çƒ­åŠ›å­¦ï¼šç†µå¢žåŠ \n",
    "   - å…°é“å°”ï¼šä½æ“¦é™¤æˆæœ¬èƒ½é‡\n",
    "   - MLï¼šåŽ‹ç¼©ä¸¢å¼ƒç»†èŠ‚\n",
    "\n",
    "4. **ç»Ÿè®¡åå·®**ï¼šå‘é«˜æ¦‚çŽ‡çŠ¶æ€æ¼”åŒ–\n",
    "   - ç‰©ç†å­¦ï¼šå¹³è¡¡æ€æœ€å¯èƒ½\n",
    "   - è®¡ç®—ï¼šçŠ¶æ€ç©ºé—´ä¸­çš„éšæœºæ¸¸èµ°\n",
    "   - MLï¼šæ¢¯åº¦ä¸‹é™è¶‹å‘æžå°å€¼\n",
    "\n",
    "## æ·±åˆ»å«ä¹‰\n",
    "\n",
    "### å¯¹äºŽç‰©ç†å­¦\n",
    "- æ—¶é—´æ˜¯æ¶ŒçŽ°çš„ï¼Œä¸æ˜¯åŸºæœ¬çš„\n",
    "- ç¬¬äºŒå®šå¾‹æ˜¯ç»Ÿè®¡çš„ï¼Œä¸æ˜¯ç»å¯¹çš„\n",
    "- ä½Žç†µåˆå§‹æ¡ä»¶æ˜¯å…³é”®è°œé¢˜\n",
    "\n",
    "### å¯¹äºŽè®¡ç®—\n",
    "- æ‰€æœ‰è®¡ç®—éƒ½æœ‰çƒ­åŠ›å­¦æˆæœ¬\n",
    "- å¯é€†è®¡ç®—å¯èƒ½\"å…è´¹\"\n",
    "- ä¿¡æ¯æ˜¯ç‰©ç†çš„ï¼ˆä¸æ˜¯æŠ½è±¡çš„ï¼‰\n",
    "\n",
    "### å¯¹äºŽæœºå™¨å­¦ä¹ \n",
    "- åŽ‹ç¼©æ˜¯æœ¬è´¨çš„ï¼ˆç”¨äºŽæ³›åŒ–ï¼‰\n",
    "- ä¿¡æ¯ç“¶é¢ˆ = å¥½çš„å½’çº³åå·®\n",
    "- é—å¿˜ï¼ˆä¸å¯é€†ï¼‰æœ‰åŠ©äºŽå­¦ä¹ \n",
    "\n",
    "### å¯¹äºŽç”Ÿå‘½\n",
    "- å¼€æ”¾ç³»ç»Ÿå¯ä»¥ç»´æŒç§©åº\n",
    "- ä½†å¿…é¡»è¾“å‡ºç†µ\n",
    "- æ­»äº¡æ˜¯çƒ­åŠ›å­¦å¿…ç„¶æ€§\n",
    "\n",
    "## ç»ˆæžé—®é¢˜\n",
    "\n",
    "**ä¸ºä»€ä¹ˆå®‡å®™è¯žç”Ÿæ—¶ç†µå¦‚æ­¤ä½Žï¼Ÿ**\n",
    "\n",
    "è¿™å•ä¸€äº‹å®žè§£é‡Šäº†ï¼š\n",
    "- æ—¶é—´ç®­å¤´\n",
    "- ä¸ºä»€ä¹ˆæ··åˆæ˜¯ä¸å¯é€†çš„\n",
    "- ä¸ºä»€ä¹ˆæˆ‘ä»¬è®°ä½è¿‡åŽ»ï¼Œä¸è®°ä½æœªæ¥\n",
    "- ä¸ºä»€ä¹ˆç”Ÿå‘½å¯èƒ½å­˜åœ¨\n",
    "- ä¸ºä»€ä¹ˆè®¡ç®—æ˜¯å¯èƒ½çš„\n",
    "\n",
    "æˆ‘ä»¬ä¸çŸ¥é“ç­”æ¡ˆã€‚ä½†è¿™æ˜¯ç‰©ç†å­¦ä¸­æœ€æ·±çš„é—®é¢˜ä¹‹ä¸€ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ä¸Žæœºå™¨å­¦ä¹ çš„è”ç³»ï¼ˆé‡æ–°å®¡è§†ï¼‰\n",
    "\n",
    "**ä¸ºä»€ä¹ˆè¿™å¯¹ AI å¾ˆé‡è¦ï¼Ÿ**\n",
    "\n",
    "1. **ä¿¡æ¯ç“¶é¢ˆ**ï¼šç¥žç»ç½‘ç»œå¿…é¡»åŽ‹ç¼© â†’ ä¸å¯é€†\n",
    "2. **å•å‘å‡½æ•°**ï¼šå®‰å…¨æ€§å–å†³äºŽè®¡ç®—ä¸å¯é€†æ€§\n",
    "3. **å…°é“å°”é™åˆ¶**ï¼šæœªæ¥ AI èƒ½æ•ˆå—çƒ­åŠ›å­¦é™åˆ¶\n",
    "4. **è®°å¿†**ï¼šå¤§è„‘/è®¡ç®—æœºå¿…é¡»æ“¦é™¤æ—§è®°å¿† â†’ ç†µæˆæœ¬\n",
    "5. **å­¦ä¹  = åŽ‹ç¼©**ï¼šå¥½çš„æ¨¡åž‹åŽ‹ç¼©æ•°æ®ä¸å¯é€†åœ°\n",
    "\n",
    "**ä¸å¯é€†æ€§ä¸æ˜¯ bugâ€”â€”å®ƒæ˜¯ç‰¹æ€§ï¼**\n",
    "\n",
    "æ²¡æœ‰å®ƒï¼š\n",
    "- æ²¡æœ‰æ³›åŒ–ï¼ˆä¼šè®°ä½ä¸€åˆ‡ï¼‰\n",
    "- æ²¡æœ‰è®¡ç®—ï¼ˆæ²¡æœ‰å•å‘å‡½æ•°ï¼‰\n",
    "- æ²¡æœ‰å®‰å…¨æ€§ï¼ˆå¯ä»¥é€†è½¬ä»»ä½•å‡½æ•°ï¼‰\n",
    "- æ²¡æœ‰å­¦ä¹ ï¼ˆæ²¡æœ‰æŠ½è±¡ï¼‰\n",
    "\n",
    "**ä½ ä¸èƒ½å–æ¶ˆå’–å•¡çš„æ··åˆã€‚ä½†å¦‚æžœä½ èƒ½ï¼Œä½ æ— æ³•æ€è€ƒå®ƒã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final visualization: The complete picture\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Central concept: The arrow of time\n",
    "ax_center = fig.add_subplot(gs[1, 1])\n",
    "ax_center.axis('off')\n",
    "ax_center.text(0.5, 0.5, 'â˜•\\n\\nThe Coffee Automaton\\n\\nIrreversibility', \n",
    "              ha='center', va='center', fontsize=20, fontweight='bold',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))\n",
    "ax_center.set_xlim(0, 1)\n",
    "ax_center.set_ylim(0, 1)\n",
    "\n",
    "# Surrounding concepts\n",
    "concepts = [\n",
    "    (\"Physics\\n\\nEntropy â†‘\\n2nd Law\", gs[0, 0]),\n",
    "    (\"Phase Space\\n\\nLiouville\\nCoarse-graining\", gs[0, 1]),\n",
    "    (\"Computation\\n\\nOne-way\\nLandauer\", gs[0, 2]),\n",
    "    (\"Recurrence\\n\\nPoincarÃ©\\ne^N time\", gs[1, 0]),\n",
    "    (\"Maxwell\\n\\nDemon\\nInfo=Physical\", gs[1, 2]),\n",
    "    (\"Biology\\n\\nLife\\nOpen system\", gs[2, 0]),\n",
    "    (\"ML\\n\\nCompression\\nBottleneck\", gs[2, 1]),\n",
    "    (\"Cosmology\\n\\nBig Bang\\nLow entropy\", gs[2, 2]),\n",
    "]\n",
    "\n",
    "colors = ['lightcoral', 'lightgreen', 'lightyellow', 'lightpink', \n",
    "         'lightcyan', 'lavender', 'peachpuff', 'thistle']\n",
    "\n",
    "for (text, pos), color in zip(concepts, colors):\n",
    "    ax = fig.add_subplot(pos)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, 0.5, text, ha='center', va='center', fontsize=12,\n",
    "           bbox=dict(boxstyle='round', facecolor=color, alpha=0.7))\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Draw arrow to center\n",
    "    ax.annotate('', xy=(0.5, 0.5), xytext=(0.5, 0.5),\n",
    "               arrowprops=dict(arrowstyle='->', lw=2, color='gray', alpha=0.5))\n",
    "\n",
    "plt.suptitle('Irreversibility: A Unifying Concept Across All Scales', \n",
    "            fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY: THE COFFEE AUTOMATON - KEY TAKEAWAYS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. FUNDAMENTAL PUZZLE:\")\n",
    "print(\"   â€¢ Microscopic laws are reversible (Newton, SchrÃ¶dinger)\")\n",
    "print(\"   â€¢ Macroscopic behavior is irreversible (coffee mixes, never unmixes)\")\n",
    "print(\"   â€¢ Resolution: Coarse-graining + statistics + low-entropy initial condition\")\n",
    "\n",
    "print(\"\\n2. MECHANISMS OF IRREVERSIBILITY:\")\n",
    "print(\"   â€¢ Coarse-graining: Losing information when grouping microstates\")\n",
    "print(\"   â€¢ Statistical mechanics: High-entropy states vastly outnumber low-entropy\")\n",
    "print(\"   â€¢ PoincarÃ© recurrence: Reversible, but on timescale e^N >> universe age\")\n",
    "\n",
    "print(\"\\n3. INFORMATION IS PHYSICAL:\")\n",
    "print(\"   â€¢ Landauer's principle: Erasing 1 bit costs k_B T ln(2) energy\")\n",
    "print(\"   â€¢ Maxwell's demon: Information gathering/erasure has entropic cost\")\n",
    "print(\"   â€¢ Computation: All irreversible operations dissipate heat\")\n",
    "\n",
    "print(\"\\n4. COMPUTATIONAL IRREVERSIBILITY:\")\n",
    "print(\"   â€¢ One-way functions: Easy forward, hard backward\")\n",
    "print(\"   â€¢ Cryptographic hashing: Many inputs â†’ same output\")\n",
    "print(\"   â€¢ Security depends on computational irreversibility\")\n",
    "\n",
    "print(\"\\n5. MACHINE LEARNING:\")\n",
    "print(\"   â€¢ Neural networks compress (information bottleneck)\")\n",
    "print(\"   â€¢ Compression = irreversible = forgetting details\")\n",
    "print(\"   â€¢ Generalization requires irreversibility!\")\n",
    "\n",
    "print(\"\\n6. LIFE AND THERMODYNAMICS:\")\n",
    "print(\"   â€¢ Life is open system: imports order, exports disorder\")\n",
    "print(\"   â€¢ Local entropy â†“, but total entropy â†‘ (2nd law satisfied)\")\n",
    "print(\"   â€¢ Death is thermodynamic inevitability\")\n",
    "\n",
    "print(\"\\n7. THE ARROW OF TIME:\")\n",
    "print(\"   â€¢ Not in the lawsâ€”in the initial conditions!\")\n",
    "print(\"   â€¢ Big Bang had extremely low entropy (why??)\")\n",
    "print(\"   â€¢ All three arrows (thermodynamic, psychological, cosmological) aligned\")\n",
    "\n",
    "print(\"\\n8. DEEP MYSTERY:\")\n",
    "print(\"   â€¢ Why was the Big Bang low-entropy?\")\n",
    "print(\"   â€¢ This single fact explains the arrow of time\")\n",
    "print(\"   â€¢ Still unsolved! One of deepest questions in physics\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nâ˜• The coffee automaton: Simple system, profound implications\")\n",
    "print(\"\\nYou can't unmix the coffee.\")\n",
    "print(\"But this irreversibility is what makes computation, life, and thought possible.\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nâœ“ Complete analysis of irreversibility finished!\")\n",
    "print(\"\\nðŸŽ“ Paper 19 implementation complete: A deep dive into the coffee automaton.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
