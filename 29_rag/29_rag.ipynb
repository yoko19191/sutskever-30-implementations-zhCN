{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 论文29：知识密集型任务的检索增强生成\n",
    "## Patrick Lewis, Ethan Perez, Aleksandra Piktus, et al., Meta AI (2020)\n",
    "\n",
    "### RAG：检索增强生成\n",
    "\n",
    "将密集检索（DPR）与序列到序列生成（BART）相结合。两全其美：外部知识 + 强大的生成能力！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams[\"font.family\"] = [\"Heiti TC\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG 架构\n",
    "\n",
    "```\n",
    "输入查询 (x)\n",
    "    ↓\n",
    "检索器 (DPR) → Top-k 文档 (z)\n",
    "    ↓\n",
    "生成器 (BART) → P(y | x, z)\n",
    "    ↓\n",
    "输出 (y)\n",
    "```\n",
    "\n",
    "**两种变体：**\n",
    "- **RAG-Sequence**：对整个序列在文档上边缘化\n",
    "- **RAG-Token**：对每个 token 在文档上边缘化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "class SimpleRetriever:\n",
    "    \"\"\"简化的密集检索器（类似 DPR）\"\"\"\n",
    "    def __init__(self, embedding_dim):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.query_encoder_W = np.random.randn(embedding_dim, embedding_dim) * 0.01\n",
    "    \n",
    "    def encode_query(self, query_tokens):\n",
    "        \"\"\"将查询编码为密集向量\"\"\"\n",
    "        # 简化：仅使用随机投影\n",
    "        query_vec = np.mean(query_tokens, axis=0)\n",
    "        encoded = np.dot(self.query_encoder_W, query_vec)\n",
    "        # L2 归一化\n",
    "        return encoded / (np.linalg.norm(encoded) + 1e-8)\n",
    "    \n",
    "    def retrieve(self, query_embedding, document_embeddings, k=5):\n",
    "        \"\"\"\n",
    "        检索 top-k 文档\n",
    "        返回：索引和概率\n",
    "        \"\"\"\n",
    "        # 计算相似度\n",
    "        similarities = np.dot(document_embeddings, query_embedding)\n",
    "        \n",
    "        # 获取 top-k\n",
    "        top_k_indices = np.argsort(similarities)[::-1][:k]\n",
    "        top_k_scores = similarities[top_k_indices]\n",
    "        \n",
    "        # 转换为概率\n",
    "        probs = softmax(top_k_scores)\n",
    "        \n",
    "        return top_k_indices, probs\n",
    "\n",
    "# 测试检索器\n",
    "embedding_dim = 64\n",
    "retriever = SimpleRetriever(embedding_dim)\n",
    "\n",
    "# 虚拟数据\n",
    "query_tokens = np.random.randn(10, embedding_dim)\n",
    "document_embeddings = np.random.randn(20, embedding_dim)\n",
    "# 归一化文档\n",
    "document_embeddings = document_embeddings / (np.linalg.norm(document_embeddings, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "query_emb = retriever.encode_query(query_tokens)\n",
    "top_indices, top_probs = retriever.retrieve(query_emb, document_embeddings, k=5)\n",
    "\n",
    "print(f\"Retrieved documents: {top_indices}\")\n",
    "print(f\"Retrieval probabilities: {top_probs}\")\n",
    "print(f\"Sum of probs: {np.sum(top_probs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成器（Seq2Seq）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGenerator:\n",
    "    \"\"\"简化的 seq2seq 生成器（类似 BART）\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder_W = np.random.randn(hidden_dim, embedding_dim) * 0.01\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_W = np.random.randn(hidden_dim, embedding_dim) * 0.01\n",
    "        self.output_W = np.random.randn(vocab_size, hidden_dim) * 0.01\n",
    "    \n",
    "    def generate_prob(self, query_tokens, doc_tokens, target_tokens):\n",
    "        \"\"\"\n",
    "        计算 P(y | x, z)，其中：\n",
    "        - x: 查询\n",
    "        - z: 文档\n",
    "        - y: 目标输出\n",
    "        \"\"\"\n",
    "        # 编码查询 + 文档\n",
    "        combined = np.concatenate([query_tokens, doc_tokens], axis=0)\n",
    "        encoder_hidden = np.tanh(np.dot(self.encoder_W, np.mean(combined, axis=0)))\n",
    "        \n",
    "        # 解码目标\n",
    "        log_prob = 0\n",
    "        for target_token in target_tokens:\n",
    "            decoder_hidden = np.tanh(np.dot(self.decoder_W, target_token))\n",
    "            \n",
    "            # 结合 encoder 和 decoder\n",
    "            combined_hidden = encoder_hidden + decoder_hidden\n",
    "            \n",
    "            # 输出分布\n",
    "            logits = np.dot(self.output_W, combined_hidden)\n",
    "            probs = softmax(logits)\n",
    "            \n",
    "            # 假设我们知道目标 token 索引（简化）\n",
    "            # 实际上，我们会计算交叉熵\n",
    "            target_idx = np.argmax(target_token)  # One-hot\n",
    "            log_prob += np.log(probs[target_idx] + 1e-8)\n",
    "        \n",
    "        return log_prob\n",
    "\n",
    "# 测试生成器\n",
    "vocab_size = 1000\n",
    "generator = SimpleGenerator(vocab_size, embedding_dim, hidden_dim=128)\n",
    "\n",
    "# 虚拟 tokens（embeddings）\n",
    "query = np.random.randn(5, embedding_dim)\n",
    "doc = np.random.randn(20, embedding_dim)\n",
    "target = np.random.randn(8, embedding_dim)\n",
    "\n",
    "log_prob = generator.generate_prob(query, doc, target)\n",
    "print(f\"\\nLog P(y | x, z): {log_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG-Sequence：在文档上边缘化\n",
    "\n",
    "$$\n",
    "P_{RAG-Seq}(y | x) = \\sum_{z \\in \\text{top-k}} P(z | x) \\cdot P(y | x, z)\n",
    "$$\n",
    "\n",
    "用每个文档生成完整序列，然后组合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSequence:\n",
    "    \"\"\"RAG-Sequence 模型\"\"\"\n",
    "    def __init__(self, retriever, generator):\n",
    "        self.retriever = retriever\n",
    "        self.generator = generator\n",
    "    \n",
    "    def forward(self, query_tokens, target_tokens, document_embeddings, documents_tokens, k=5):\n",
    "        \"\"\"\n",
    "        RAG-Sequence 前向传播\n",
    "        \n",
    "        P(y|x) = Σ_z P(z|x) * P(y|x,z)\n",
    "        \"\"\"\n",
    "        # 检索文档\n",
    "        query_emb = self.retriever.encode_query(query_tokens)\n",
    "        doc_indices, doc_probs = self.retriever.retrieve(query_emb, document_embeddings, k=k)\n",
    "        \n",
    "        # 在文档上边缘化\n",
    "        total_prob = 0\n",
    "        \n",
    "        for doc_idx, p_z_given_x in zip(doc_indices, doc_probs):\n",
    "            # 获取文档 tokens\n",
    "            doc_tokens = documents_tokens[doc_idx]\n",
    "            \n",
    "            # P(y | x, z)\n",
    "            log_p_y_given_xz = self.generator.generate_prob(query_tokens, doc_tokens, target_tokens)\n",
    "            p_y_given_xz = np.exp(log_p_y_given_xz)\n",
    "            \n",
    "            # P(z|x) * P(y|x,z)\n",
    "            total_prob += p_z_given_x * p_y_given_xz\n",
    "        \n",
    "        return np.log(total_prob + 1e-8), doc_indices, doc_probs\n",
    "\n",
    "# 创建 RAG-Sequence 模型\n",
    "rag_seq = RAGSequence(retriever, generator)\n",
    "\n",
    "# 生成虚拟文档\n",
    "num_docs = 20\n",
    "documents_tokens = [np.random.randn(15, embedding_dim) for _ in range(num_docs)]\n",
    "\n",
    "# 测试\n",
    "log_prob, used_docs, used_probs = rag_seq.forward(\n",
    "    query_tokens=query,\n",
    "    target_tokens=target,\n",
    "    document_embeddings=document_embeddings,\n",
    "    documents_tokens=documents_tokens,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "print(\"\\nRAG-Sequence:\")\n",
    "print(f\"Log P(y|x): {log_prob:.4f}\")\n",
    "print(f\"Used documents: {used_docs}\")\n",
    "print(f\"Document weights: {used_probs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG-Token：对每个 Token 边缘化\n",
    "\n",
    "$$\n",
    "P_{RAG-Token}(y | x) = \\prod_{i=1}^{|y|} \\sum_{z \\in \\text{top-k}} P(z | x) \\cdot P(y_i | x, z, y_{<i})\n",
    "$$\n",
    "\n",
    "可以为不同的 token 使用不同的文档！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGToken:\n",
    "    \"\"\"RAG-Token 模型（简化）\"\"\"\n",
    "    def __init__(self, retriever, generator):\n",
    "        self.retriever = retriever\n",
    "        self.generator = generator\n",
    "    \n",
    "    def forward_token(self, query_tokens, target_token, document_embeddings, documents_tokens, k=5):\n",
    "        \"\"\"\n",
    "        计算单个 token 的 P(y_i | x)\n",
    "        \n",
    "        P(y_i | x) = Σ_z P(z|x) * P(y_i|x,z)\n",
    "        \"\"\"\n",
    "        # 检索文档\n",
    "        query_emb = self.retriever.encode_query(query_tokens)\n",
    "        doc_indices, doc_probs = self.retriever.retrieve(query_emb, document_embeddings, k=k)\n",
    "        \n",
    "        # 对此 token 边缘化\n",
    "        token_prob = 0\n",
    "        \n",
    "        for doc_idx, p_z_given_x in zip(doc_indices, doc_probs):\n",
    "            doc_tokens = documents_tokens[doc_idx]\n",
    "            \n",
    "            # P(y_i | x, z) - 简化\n",
    "            log_p = self.generator.generate_prob(query_tokens, doc_tokens, [target_token])\n",
    "            p_yi_given_xz = np.exp(log_p)\n",
    "            \n",
    "            token_prob += p_z_given_x * p_yi_given_xz\n",
    "        \n",
    "        return token_prob, doc_indices, doc_probs\n",
    "    \n",
    "    def forward(self, query_tokens, target_tokens, document_embeddings, documents_tokens, k=5):\n",
    "        \"\"\"\n",
    "        完整序列概率\n",
    "        \n",
    "        P(y|x) = ∏_i P(y_i|x)\n",
    "        \"\"\"\n",
    "        log_prob_total = 0\n",
    "        \n",
    "        for target_token in target_tokens:\n",
    "            token_prob, _, _ = self.forward_token(\n",
    "                query_tokens, target_token, document_embeddings, documents_tokens, k\n",
    "            )\n",
    "            log_prob_total += np.log(token_prob + 1e-8)\n",
    "        \n",
    "        return log_prob_total\n",
    "\n",
    "# 创建 RAG-Token 模型\n",
    "rag_token = RAGToken(retriever, generator)\n",
    "\n",
    "# 测试\n",
    "log_prob_token = rag_token.forward(\n",
    "    query_tokens=query,\n",
    "    target_tokens=target,\n",
    "    document_embeddings=document_embeddings,\n",
    "    documents_tokens=documents_tokens,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "print(\"\\nRAG-Token:\")\n",
    "print(f\"Log P(y|x): {log_prob_token:.4f}\")\n",
    "print(\"\\nDifference: RAG-Token can use different docs per token!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合成 QA 示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create more realistic example\n",
    "knowledge_base = [\n",
    "    \"The Eiffel Tower was built in 1889 by Gustave Eiffel.\",\n",
    "    \"Paris is the capital of France and has a population of 2.2 million.\",\n",
    "    \"The Statue of Liberty was a gift from France to the United States.\",\n",
    "    \"Mount Everest is 8,849 meters tall and located in the Himalayas.\",\n",
    "    \"The Amazon River flows through South America for 6,400 kilometers.\",\n",
    "]\n",
    "\n",
    "qa_pairs = [\n",
    "    (\"When was the Eiffel Tower built?\", \"1889\", 0),\n",
    "    (\"What is the height of Mount Everest?\", \"8,849 meters\", 3),\n",
    "    (\"How long is the Amazon River?\", \"6,400 kilometers\", 4),\n",
    "]\n",
    "\n",
    "print(\"Knowledge Base:\")\n",
    "for i, doc in enumerate(knowledge_base):\n",
    "    print(f\"  {i}. {doc}\")\n",
    "\n",
    "print(\"\\nQA Pairs:\")\n",
    "for q, a, doc_idx in qa_pairs:\n",
    "    print(f\"  Q: {q}\")\n",
    "    print(f\"  A: {a}\")\n",
    "    print(f\"  Relevant doc: #{doc_idx}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化 RAG 架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "def draw_rag_variant(ax, title, is_token=False):\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(0, 12)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Query\n",
    "    ax.add_patch(plt.Rectangle((4, 10.5), 2, 0.8, fill=True, \n",
    "                               color='lightblue', ec='black', linewidth=2))\n",
    "    ax.text(5, 10.9, 'Query (x)', ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Retriever\n",
    "    ax.add_patch(plt.Rectangle((3.5, 9), 3, 1, fill=True, \n",
    "                               color='lightgreen', ec='black', linewidth=2))\n",
    "    ax.text(5, 9.5, 'Retriever\\n(DPR)', ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "    ax.arrow(5, 10.5, 0, -0.3, head_width=0.2, head_length=0.1, fc='black', ec='black', linewidth=2)\n",
    "    \n",
    "    # Retrieved documents\n",
    "    doc_positions = [2, 4, 6, 8]\n",
    "    ax.text(5, 7.8, 'Top-k Documents', ha='center', fontsize=10, fontweight='bold')\n",
    "    for i, x in enumerate(doc_positions[:3]):\n",
    "        ax.add_patch(plt.Rectangle((x-0.4, 6.5), 0.8, 1, fill=True, \n",
    "                                   color='lightyellow', ec='black', linewidth=1.5))\n",
    "        ax.text(x, 7, f'z{i+1}', ha='center', va='center', fontsize=9)\n",
    "        # Arrow from retriever\n",
    "        ax.plot([5, x], [9, 7.5], 'k--', alpha=0.5, linewidth=1)\n",
    "    \n",
    "    if not is_token:\n",
    "        # RAG-Sequence: each doc generates full sequence\n",
    "        y_positions = [2, 4, 6]\n",
    "        for i, (dx, dy) in enumerate(zip(doc_positions[:3], y_positions)):\n",
    "            # Generator per document\n",
    "            ax.add_patch(plt.Rectangle((dy-0.5, 4.5), 1, 0.8, fill=True, \n",
    "                                       color='lightcoral', ec='black', linewidth=1.5))\n",
    "            ax.text(dy, 4.9, f'Gen', ha='center', va='center', fontsize=8)\n",
    "            ax.arrow(dx, 6.5, dy-dx, -1.5, head_width=0.15, head_length=0.1, \n",
    "                    fc='gray', ec='gray', linewidth=1, alpha=0.6)\n",
    "            \n",
    "            # Output sequence\n",
    "            ax.add_patch(plt.Rectangle((dy-0.6, 3), 1.2, 0.6, fill=True, \n",
    "                                       color='wheat', ec='black', linewidth=1))\n",
    "            ax.text(dy, 3.3, f'y', ha='center', va='center', fontsize=8)\n",
    "            ax.arrow(dy, 4.5, 0, -0.8, head_width=0.12, head_length=0.08, \n",
    "                    fc='black', ec='black', linewidth=1)\n",
    "        \n",
    "        # Combine\n",
    "        ax.add_patch(plt.Rectangle((4, 1.2), 2, 0.8, fill=True, \n",
    "                                   color='plum', ec='black', linewidth=2))\n",
    "        ax.text(5, 1.6, 'Σ P(z|x)P(y|x,z)', ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "        for dy in y_positions:\n",
    "            ax.plot([dy, 5], [3, 2], 'k-', alpha=0.5, linewidth=1.5)\n",
    "    else:\n",
    "        # RAG-Token: combine docs for each token\n",
    "        token_y = 4.5\n",
    "        for t in range(3):\n",
    "            tx = 2 + t * 2.5\n",
    "            \n",
    "            # Token position\n",
    "            ax.add_patch(plt.Rectangle((tx-0.4, token_y), 0.8, 0.6, fill=True, \n",
    "                                       color='lightcoral', ec='black', linewidth=1.5))\n",
    "            ax.text(tx, token_y+0.3, f'y{t+1}', ha='center', va='center', fontsize=9)\n",
    "            \n",
    "            # Arrows from all docs\n",
    "            for dx in doc_positions[:3]:\n",
    "                ax.plot([dx, tx], [6.5, token_y+0.6], 'k--', alpha=0.3, linewidth=0.8)\n",
    "        \n",
    "        # Final output\n",
    "        ax.add_patch(plt.Rectangle((3.5, 2.5), 3, 0.8, fill=True, \n",
    "                                   color='plum', ec='black', linewidth=2))\n",
    "        ax.text(5, 2.9, '∏ Σ P(z|x)P(yi|x,z)', ha='center', va='center', \n",
    "               fontsize=9, fontweight='bold')\n",
    "        ax.arrow(4, token_y, 0.8, -1.3, head_width=0.15, head_length=0.1, \n",
    "                fc='black', ec='black', linewidth=1.5, alpha=0.5)\n",
    "    \n",
    "    # Final answer\n",
    "    ax.add_patch(plt.Rectangle((4, 0.3), 2, 0.6, fill=True, \n",
    "                               color='lightgreen', ec='black', linewidth=2))\n",
    "    ax.text(5, 0.6, 'Answer', ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "    ax.arrow(5, 1.2 if not is_token else 2.5, 0, \n",
    "            -0.2 if not is_token else -1.5, \n",
    "            head_width=0.2, head_length=0.1, fc='green', ec='green', linewidth=2)\n",
    "\n",
    "draw_rag_variant(axes[0], 'RAG-Sequence', is_token=False)\n",
    "draw_rag_variant(axes[1], 'RAG-Token', is_token=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比较 RAG 变体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟概率用于可视化\n",
    "n_docs = 5\n",
    "n_tokens = 8\n",
    "\n",
    "# RAG-Sequence：所有 token 使用相同的文档权重\n",
    "doc_weights_seq = softmax(np.random.randn(n_docs))\n",
    "weights_seq_matrix = np.tile(doc_weights_seq, (n_tokens, 1))\n",
    "\n",
    "# RAG-Token：每个 token 使用不同的文档权重\n",
    "weights_token_matrix = np.array([softmax(np.random.randn(n_docs)) for _ in range(n_tokens)])\n",
    "\n",
    "# 可视化\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "im1 = ax1.imshow(weights_seq_matrix.T, cmap='YlOrRd', aspect='auto', vmin=0, vmax=1)\n",
    "ax1.set_xlabel('Output Token Position', fontsize=12)\n",
    "ax1.set_ylabel('Document', fontsize=12)\n",
    "ax1.set_title('RAG-Sequence\\n(Same docs for all tokens)', fontsize=13, fontweight='bold')\n",
    "plt.colorbar(im1, ax=ax1, label='P(z|x)')\n",
    "\n",
    "im2 = ax2.imshow(weights_token_matrix.T, cmap='YlOrRd', aspect='auto', vmin=0, vmax=1)\n",
    "ax2.set_xlabel('Output Token Position', fontsize=12)\n",
    "ax2.set_ylabel('Document', fontsize=12)\n",
    "ax2.set_title('RAG-Token\\n(Different docs per token)', fontsize=13, fontweight='bold')\n",
    "plt.colorbar(im2, ax=ax2, label='P(z|x)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRAG-Sequence: 更一致（使用相同的知识）\")\n",
    "print(\"RAG-Token: 更灵活（可以混合知识源）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键要点\n",
    "\n",
    "### RAG 架构：\n",
    "\n",
    "**组件**：\n",
    "1. **检索器**：密集检索（DPR 风格）\n",
    "   - 查询编码器：$q_{emb} = E_Q(x)$\n",
    "   - 文档编码器：$d_{emb} = E_D(z)$\n",
    "   - 检索：$P(z|x) \\propto \\exp(q_{emb} \\cdot d_{emb})$\n",
    "\n",
    "2. **生成器**：Seq2seq 模型（BART）\n",
    "   - 输入：查询 $x$ + 文档 $z$\n",
    "   - 输出：$P(y | x, z)$\n",
    "\n",
    "### RAG-Sequence：\n",
    "\n",
    "$$\n",
    "P_{RAG-Seq}(y | x) = \\sum_{z \\in \\text{top-k}} P(z | x) \\cdot P_{seq2seq}(y | x, z)\n",
    "$$\n",
    "\n",
    "**过程**：\n",
    "1. 检索 top-k 文档\n",
    "2. 用每个文档生成完整序列\n",
    "3. 序列的加权和\n",
    "\n",
    "**特点**：\n",
    "- 每个文档生成完整答案\n",
    "- 更一致（每个序列使用单一知识源）\n",
    "- 更适合事实性 QA\n",
    "\n",
    "### RAG-Token：\n",
    "\n",
    "$$\n",
    "P_{RAG-Token}(y | x) = \\prod_{i=1}^{|y|} \\left( \\sum_{z \\in \\text{top-k}} P(z | x) \\cdot P(y_i | x, z, y_{<i}) \\right)\n",
    "$$\n",
    "\n",
    "**过程**：\n",
    "1. 检索 top-k 文档（所有 token 相同）\n",
    "2. 对每个 token：在文档上边缘化\n",
    "3. 不同文档可以为不同 token 做出贡献\n",
    "\n",
    "**特点**：\n",
    "- 可以混合来自多个文档的信息\n",
    "- 更灵活的生成\n",
    "- 更适合长文本生成\n",
    "\n",
    "### 训练：\n",
    "\n",
    "**端到端**：\n",
    "```\n",
    "Loss = -log P(y* | x)\n",
    "```\n",
    "\n",
    "梯度流经：\n",
    "- 生成器（BART 参数）\n",
    "- 查询编码器（检索器参数）\n",
    "\n",
    "**文档编码器**：通常冻结（预索引）\n",
    "\n",
    "### 实现细节：\n",
    "\n",
    "**来自论文**：\n",
    "- 检索器：使用 BERT-base 的 DPR\n",
    "- 生成器：BART-large（400M 参数）\n",
    "- 知识库：Wikipedia（21M 段落）\n",
    "- Top-k：k=5 或 k=10\n",
    "- 索引：FAISS 用于快速检索\n",
    "\n",
    "### 结果：\n",
    "\n",
    "**Natural Questions (Open)**：\n",
    "- BART（无检索）：27.0% EM\n",
    "- RAG-Sequence：44.5% EM\n",
    "- RAG-Token：44.1% EM\n",
    "\n",
    "**TriviaQA**：\n",
    "- BART：50.1%\n",
    "- RAG：56.8%\n",
    "\n",
    "**WebQuestions**：\n",
    "- BART：27.6%\n",
    "- RAG：45.2%\n",
    "\n",
    "### RAG vs 基线：\n",
    "\n",
    "| 模型 | 知识 | 参数化 | 性能 |\n",
    "|-------|-----------|------------|-------------|\n",
    "| T5-11B | 记忆化 | ✓ | 良好 |\n",
    "| REALM | 检索 | 混合 | 更好 |\n",
    "| **RAG** | **检索** | **✓** | **最佳** |\n",
    "\n",
    "### 优势：\n",
    "\n",
    "- ✅ **事实准确性**：访问外部知识\n",
    "- ✅ **可扩展性**：无需重新训练即可添加知识\n",
    "- ✅ **可解释性**：可以检查检索到的文档\n",
    "- ✅ **效率**：比纯参数化模型更小\n",
    "- ✅ **最新性**：更新索引，而非模型权重\n",
    "\n",
    "### 局限性：\n",
    "\n",
    "- ❌ **检索错误**：错误文档 → 错误答案\n",
    "- ❌ **延迟**：检索增加开销\n",
    "- ❌ **索引维护**：更新时需要重新编码\n",
    "- ❌ **内存**：需要完整文档索引\n",
    "\n",
    "### 何时使用：\n",
    "\n",
    "**RAG-Sequence**：\n",
    "- 事实性 QA\n",
    "- 简短答案\n",
    "- 单一来源足够时\n",
    "\n",
    "**RAG-Token**：\n",
    "- 长文本生成\n",
    "- 多跳推理\n",
    "- 组合多个来源\n",
    "\n",
    "### 现代扩展：\n",
    "\n",
    "- **RETRO** (DeepMind)：在每一层检索\n",
    "- **Atlas** (Meta)：改进的训练\n",
    "- **Toolformer**：通过 API 调用检索\n",
    "- **WebGPT**：交互式检索\n",
    "- **Self-RAG**：自反思检索\n",
    "\n",
    "### 生产建议：\n",
    "\n",
    "1. **混合排序**：结合检索 + 重排序\n",
    "2. **缓存**：为常见查询预检索\n",
    "3. **异步**：在生成时检索\n",
    "4. **回退**：如果检索失败则使用参数化生成\n",
    "5. **监控**：跟踪检索质量\n",
    "\n",
    "### 应用：\n",
    "\n",
    "- 开放域 QA（Google、Bing）\n",
    "- 带知识库的聊天机器人\n",
    "- 文档 QA\n",
    "- 事实核查\n",
    "- 研究助手\n",
    "- 客户支持\n",
    "\n",
    "### 关键洞察：\n",
    "\n",
    "**RAG = 两全其美**\n",
    "- 参数化知识（生成能力）\n",
    "- 非参数化知识（外部检索）\n",
    "- 端到端可微分\n",
    "- 实用且有效！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
