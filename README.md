# Sutskever 30 - å®Œæ•´å®ç°å¥—ä»¶

**Ilya Sutskever æ¨èçš„ 30 ç¯‡åŸºç¡€è®ºæ–‡çš„ç»¼åˆæ•™å­¦å®ç°**

[![Implementations](https://img.shields.io/badge/å®ç°-30%2F30-brightgreen)](https://github.com/yoko19191/sutskever-30-implementations-zhCN)
[![Coverage](https://img.shields.io/badge/è¦†ç›–ç‡-100%25-blue)](https://github.com/yoko19191/sutskever-30-implementations-zhCN)
[![Python](https://img.shields.io/badge/Python-ä»…NumPy-yellow)](https://numpy.org/)

## æ¦‚è¿°

æœ¬ä»“åº“åŒ…å«äº† Ilya Sutskever è‘—åé˜…è¯»åˆ—è¡¨ä¸­è®ºæ–‡çš„è¯¦ç»†æ•™å­¦å®ç°â€”â€”ä»–å‘Šè¯‰ John Carmackï¼Œè¿™ä¸ªæ”¶è—å°†æ•™ä¼šä½ æ·±åº¦å­¦ä¹ ä¸­"90% é‡è¦çš„å†…å®¹"ã€‚

### å…³äºé˜…è¯»åˆ—è¡¨

**å‡ºå¤„**ï¼šè¿™ä¸ªé˜…è¯»åˆ—è¡¨æœ€åˆç”± Ilya Sutskeverï¼ˆOpenAI è”åˆåˆ›å§‹äººå…¼é¦–å¸­ç§‘å­¦å®¶ï¼‰æ¨èç»™ John Carmackã€‚è¯¥åˆ—è¡¨åœ¨ç¤¾åŒºä¸­å¹¿æ³›æµä¼ ï¼Œè¢«è®¤ä¸ºæ˜¯æ·±åº¦å­¦ä¹ é¢†åŸŸçš„æ ¸å¿ƒé˜…è¯»ææ–™ã€‚

**è®ºæ–‡æ—¶é—´èŒƒå›´**ï¼šé˜…è¯»åˆ—è¡¨ä¸­çš„è®ºæ–‡æ¶µç›–äº†ä» 2012 å¹´ï¼ˆAlexNetï¼‰åˆ° 2023 å¹´ï¼ˆLost in the Middleï¼‰çš„æ·±åº¦å­¦ä¹ å‘å±•å†ç¨‹ï¼Œåæ˜ äº†è¯¥é¢†åŸŸåœ¨è¿‡å»åä½™å¹´ä¸­çš„å…³é”®è¿›å±•ã€‚

**è®ºæ–‡æ›´æ–°æˆªæ­¢æ—¶é—´**ï¼šæœ¬é˜…è¯»åˆ—è¡¨çš„è®ºæ–‡æ›´æ–°æˆªæ­¢è‡³ **2023 å¹´**ã€‚æœ€æ–°çš„è®ºæ–‡æ˜¯è®ºæ–‡ 30ï¼šLost in the Middle (2023)ï¼Œè¯¥è®ºæ–‡æ­ç¤ºäº†è¯­è¨€æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡ä¸­çš„ä½ç½®åå·®é—®é¢˜ã€‚

**å‚è€ƒèµ„æº**ï¼š

- åŸå§‹é˜…è¯»åˆ—è¡¨æ•´ç†ï¼š[Ilya Sutskever çš„é˜…è¯»åˆ—è¡¨ (GitHub)](https://github.com/dzyim/ilya-sutskever-recommended-reading)
- ç›¸å…³è®¨è®ºå’Œè§£è¯»ï¼š[Aman çš„ AI æœŸåˆŠ - Sutskever 30 å…¥é—¨](https://aman.ai/primers/ai/top-30-papers/)

æ¯ä¸ªå®ç°ï¼š

- âœ… å¼•ç”¨åŸæ–‡å‡ºå¤„
- âœ… ä»…ä½¿ç”¨ NumPyï¼ˆæ— æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼‰ä»¥ç¡®ä¿æ•™å­¦æ¸…æ™°åº¦
- âœ… åŒ…å«åˆæˆ/å¼•å¯¼æ•°æ®ä»¥ä¾¿ç«‹å³æ‰§è¡Œ
- âœ… æä¾›ä¸°å¯Œçš„å¯è§†åŒ–å’Œè§£é‡Š
- âœ… å±•ç¤ºæ¯ç¯‡è®ºæ–‡çš„æ ¸å¿ƒæ¦‚å¿µ
- âœ… åœ¨ Jupyter notebooks ä¸­è¿è¡Œä»¥å®ç°äº¤äº’å¼å­¦ä¹ 

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£… uv (å¦‚æœå°šæœªå®‰è£…)

**macOS / Linux:**

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Windows:**

```powershell
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### 2. è¿è¡Œé¡¹ç›®

```bash
# å…‹éš†ä»“åº“
git clone git@github.com:yoko19191/sutskever-30-implementations-zhCN.git

# è¿›å…¥ç›®å½•
cd sutskever-30-implementations-zhCN

# ä½¿ç”¨ uv åŒæ­¥ä¾èµ–
uv sync

# è¿è¡Œä»»ä½• notebook
uv run jupyter notebook 02_char_rnn_karpathy.ipynb
```

## Sutskever 30 ç¯‡è®ºæ–‡

### åŸºç¡€æ¦‚å¿µï¼ˆè®ºæ–‡ 1-5ï¼‰

| # | è®ºæ–‡                                                     | Notebook                              | æ ¸å¿ƒæ¦‚å¿µ                             |
| - | -------------------------------------------------------- | ------------------------------------- | ------------------------------------ |
| 1 | å¤æ‚æ€§åŠ¨åŠ›å­¦ç¬¬ä¸€å®šå¾‹ (The First Law of Complexodynamics) | âœ…`01_complexity_dynamics.ipynb`    | ç†µ (Entropy)ã€å¤æ‚æ€§å¢é•¿ã€ç»†èƒè‡ªåŠ¨æœº |
| 2 | RNN çš„æƒŠäººæœ‰æ•ˆæ€§                                         | âœ…`02_char_rnn_karpathy.ipynb`      | å­—ç¬¦çº§æ¨¡å‹ã€RNN åŸºç¡€ã€æ–‡æœ¬ç”Ÿæˆ       |
| 3 | ç†è§£ LSTM ç½‘ç»œ                                           | âœ…`03_lstm_understanding.ipynb`     | é—¨æ§ (Gates)ã€é•¿æœŸè®°å¿†ã€æ¢¯åº¦æµ       |
| 4 | RNN æ­£åˆ™åŒ–                                               | âœ…`04_rnn_regularization.ipynb`     | åºåˆ—ä¸¢å¼ƒ (Dropout)ã€å˜åˆ†ä¸¢å¼ƒ         |
| 5 | ä¿æŒç¥ç»ç½‘ç»œç®€å•                                         | âœ…`05_neural_network_pruning.ipynb` | MDL åŸåˆ™ã€æƒé‡å‰ªæã€90%+ ç¨€ç–æ€§      |

### æ¶æ„ä¸æœºåˆ¶ï¼ˆè®ºæ–‡ 6-15ï¼‰

| #  | è®ºæ–‡                                                           | Notebook                                 | æ ¸å¿ƒæ¦‚å¿µ                                         |
| -- | -------------------------------------------------------------- | ---------------------------------------- | ------------------------------------------------ |
| 6  | æŒ‡é’ˆç½‘ç»œ (Pointer Networks)                                    | âœ…`06_pointer_networks.ipynb`          | æ³¨æ„åŠ›ä½œä¸ºæŒ‡é’ˆã€ç»„åˆä¼˜åŒ–é—®é¢˜                     |
| 7  | ImageNet/AlexNet                                               | âœ…`07_alexnet_cnn.ipynb`               | CNNã€å·ç§¯ã€æ•°æ®å¢å¼º                              |
| 8  | é¡ºåºå¾ˆé‡è¦ï¼šé›†åˆçš„åºåˆ—åˆ°åºåˆ— (Order Matters: Seq2Seq for Sets) | âœ…`08_seq2seq_for_sets.ipynb`          | é›†åˆç¼–ç ã€æ’åˆ—ä¸å˜æ€§ã€æ³¨æ„åŠ›æ± åŒ–                 |
| 9  | GPipe                                                          | âœ…`09_gpipe.ipynb`                     | æµæ°´çº¿å¹¶è¡Œã€å¾®æ‰¹æ¬¡ã€é‡è®¡ç®—                       |
| 10 | æ·±åº¦æ®‹å·®å­¦ä¹  (ResNet)                                          | âœ…`10_resnet_deep_residual.ipynb`      | è·³è·ƒè¿æ¥ã€æ¢¯åº¦é«˜é€Ÿå…¬è·¯                           |
| 11 | æ‰©å¼ å·ç§¯                                                       | âœ…`11_dilated_convolutions.ipynb`      | æ„Ÿå—é‡ã€å¤šå°ºåº¦                                   |
| 12 | ç¥ç»æ¶ˆæ¯ä¼ é€’ (GNNs)                                            | âœ…`12_graph_neural_networks.ipynb`     | å›¾ç½‘ç»œã€æ¶ˆæ¯ä¼ é€’                                 |
| 13 | **Attention Is All You Need**                            | âœ…`13_attention_is_all_you_need.ipynb` | Transformers (Transformer)ã€è‡ªæ³¨æ„åŠ›ã€å¤šå¤´æ³¨æ„åŠ› |
| 14 | ç¥ç»æœºå™¨ç¿»è¯‘                                                   | âœ…`14_bahdanau_attention.ipynb`        | åºåˆ—åˆ°åºåˆ— (Seq2seq)ã€Bahdanau æ³¨æ„åŠ›            |
| 15 | ResNet ä¸­çš„æ’ç­‰æ˜ å°„                                            | âœ…`15_identity_mappings_resnet.ipynb`  | é¢„æ¿€æ´»ã€æ¢¯åº¦æµ                                   |

### é«˜çº§ä¸»é¢˜ï¼ˆè®ºæ–‡ 16-22ï¼‰

| #  | è®ºæ–‡                              | Notebook                               | æ ¸å¿ƒæ¦‚å¿µ                                        |
| -- | --------------------------------- | -------------------------------------- | ----------------------------------------------- |
| 16 | å…³ç³»æ¨ç† (Relational Reasoning)   | âœ…`16_relational_reasoning.ipynb`    | å…³ç³»ç½‘ç»œã€æˆå¯¹å‡½æ•°                              |
| 17 | **å˜åˆ†æœ‰æŸè‡ªç¼–ç å™¨**        | âœ…`17_variational_autoencoder.ipynb` | VAEã€ELBOã€é‡å‚æ•°åŒ–æŠ€å·§                         |
| 18 | **å…³ç³» RNN**                | âœ…`18_relational_rnn.ipynb`          | å…³ç³»è®°å¿†ã€å¤šå¤´è‡ªæ³¨æ„åŠ›ã€æ‰‹åŠ¨åå‘ä¼ æ’­ (~1100 è¡Œ) |
| 19 | å’–å•¡è‡ªåŠ¨æœº (The Coffee Automaton) | âœ…`19_coffee_automaton.ipynb`        | ä¸å¯é€†æ€§ã€ç†µã€æ—¶é—´ç®­å¤´ã€Landauer åŸç†           |
| 20 | **ç¥ç»å›¾çµæœº**              | âœ…`20_neural_turing_machine.ipynb`   | å¤–éƒ¨è®°å¿†ã€å¯å¾®åˆ†å¯»å€                            |
| 21 | Deep Speech 2 (CTC)               | âœ…`21_ctc_speech.ipynb`              | CTC æŸå¤±ã€è¯­éŸ³è¯†åˆ«                              |
| 22 | Scaling Law                       | âœ…`22_scaling_laws.ipynb`            | å¹‚å¾‹ã€è®¡ç®—æœ€ä¼˜è®­ç»ƒ                              |

### ç†è®ºä¸å…ƒå­¦ä¹ ï¼ˆè®ºæ–‡ 23-30ï¼‰

| #  | è®ºæ–‡                                          | Notebook                                  | æ ¸å¿ƒæ¦‚å¿µ                                                    |
| -- | --------------------------------------------- | ----------------------------------------- | ----------------------------------------------------------- |
| 23 | MDL åŸåˆ™                                      | âœ…`23_mdl_principle.ipynb`              | ä¿¡æ¯è®ºã€æ¨¡å‹é€‰æ‹©ã€å‹ç¼©                                      |
| 24 | **æœºå™¨è¶…çº§æ™ºèƒ½**                        | âœ…`24_machine_super_intelligence.ipynb` | é€šç”¨ AIã€AIXIã€Solomonoff å½’çº³ã€æ™ºèƒ½åº¦é‡ã€è‡ªæˆ‘æ”¹è¿›          |
| 25 | Kolmogorov å¤æ‚æ€§                             | âœ…`25_kolmogorov_complexity.ipynb`      | å‹ç¼©ã€ç®—æ³•éšæœºæ€§ã€é€šç”¨å…ˆéªŒ                                  |
| 26 | **CS231n: CNN è§†è§‰è¯†åˆ«**                | âœ…`26_cs231n_cnn_fundamentals.ipynb`    | å›¾åƒåˆ†ç±»æµç¨‹ã€kNN/çº¿æ€§/NN/CNNã€åå‘ä¼ æ’­ã€ä¼˜åŒ–ã€è°ƒä¼˜ç¥ç»ç½‘ç»œ |
| 27 | å¤šä»¤ç‰Œé¢„æµ‹ (Multi-token Prediction)           | âœ…`27_multi_token_prediction.ipynb`     | å¤šä¸ªæœªæ¥ä»¤ç‰Œã€æ ·æœ¬æ•ˆç‡ã€å¿« 2-3 å€                           |
| 28 | å¯†é›†æ®µè½æ£€ç´¢                                  | âœ…`28_dense_passage_retrieval.ipynb`    | åŒç¼–ç å™¨ã€MIPSã€æ‰¹æ¬¡å†…è´Ÿæ ·æœ¬                                |
| 29 | æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-Augmented Generation) | âœ…`29_rag.ipynb`                        | RAG-Sequenceã€RAG-Tokenã€çŸ¥è¯†æ£€ç´¢                           |
| 30 | è¿·å¤±åœ¨ä¸­é—´ (Lost in the Middle)               | âœ…`30_lost_in_middle.ipynb`             | ä½ç½®åå·®ã€é•¿ä¸Šä¸‹æ–‡ã€U å‹æ›²çº¿                                |

## ç²¾é€‰å®ç°

### ğŸŒŸ å¿…è¯» Notebooks

è¿™äº›å®ç°æ¶µç›–äº†æœ€æœ‰å½±å“åŠ›çš„è®ºæ–‡å¹¶å±•ç¤ºäº†æ ¸å¿ƒæ·±åº¦å­¦ä¹ æ¦‚å¿µï¼š

#### åŸºç¡€

1. **`02_char_rnn_karpathy.ipynb`** - å­—ç¬¦çº§ RNN

   - ä»é›¶æ„å»º RNN
   - ç†è§£é€šè¿‡æ—¶é—´çš„åå‘ä¼ æ’­
   - ç”Ÿæˆæ–‡æœ¬
2. **`03_lstm_understanding.ipynb`** - LSTM ç½‘ç»œ

   - å®ç°é—å¿˜/è¾“å…¥/è¾“å‡ºé—¨
   - å¯è§†åŒ–é—¨æ§æ¿€æ´»
   - ä¸æ™®é€š RNN æ¯”è¾ƒ
3. **`04_rnn_regularization.ipynb`** - RNN æ­£åˆ™åŒ–

   - RNN çš„å˜åˆ†ä¸¢å¼ƒ
   - æ­£ç¡®çš„ä¸¢å¼ƒæ”¾ç½®
   - è®­ç»ƒæ”¹è¿›
4. **`05_neural_network_pruning.ipynb`** - ç½‘ç»œå‰ªæä¸ MDL

   - åŸºäºå¹…åº¦çš„å‰ªæ
   - è¿­ä»£å‰ªæä¸å¾®è°ƒ
   - 90%+ ç¨€ç–æ€§ä¸”æŸå¤±æœ€å°
   - æœ€å°æè¿°é•¿åº¦åŸåˆ™

#### è®¡ç®—æœºè§†è§‰

5. **`07_alexnet_cnn.ipynb`** - CNN ä¸ AlexNet

   - ä»é›¶å®ç°å·ç§¯å±‚
   - æœ€å¤§æ± åŒ–å’Œ ReLU
   - æ•°æ®å¢å¼ºæŠ€æœ¯
6. **`10_resnet_deep_residual.ipynb`** - ResNet

   - è·³è·ƒè¿æ¥è§£å†³é€€åŒ–é—®é¢˜
   - æ¢¯åº¦æµå¯è§†åŒ–
   - æ’ç­‰æ˜ å°„ç›´è§‰
7. **`15_identity_mappings_resnet.ipynb`** - é¢„æ¿€æ´» ResNet

   - é¢„æ¿€æ´» vs åæ¿€æ´»
   - æ›´å¥½çš„æ¢¯åº¦æµ
   - è®­ç»ƒ 1000+ å±‚ç½‘ç»œ
8. **`11_dilated_convolutions.ipynb`** - æ‰©å¼ å·ç§¯

   - å¤šå°ºåº¦æ„Ÿå—é‡
   - æ— éœ€æ± åŒ–
   - è¯­ä¹‰åˆ†å‰²

#### æ³¨æ„åŠ›æœºåˆ¶ä¸ Transformers

9. **`14_bahdanau_attention.ipynb`** - ç¥ç»æœºå™¨ç¿»è¯‘

   - åŸå§‹æ³¨æ„åŠ›æœºåˆ¶
   - å¸¦å¯¹é½çš„åºåˆ—åˆ°åºåˆ— (Seq2seq)
   - æ³¨æ„åŠ›å¯è§†åŒ–
10. **`13_attention_is_all_you_need.ipynb`** - Transformers

    - ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›
    - å¤šå¤´æ³¨æ„åŠ›
    - ä½ç½®ç¼–ç 
    - ç°ä»£ LLM çš„åŸºç¡€
11. **`06_pointer_networks.ipynb`** - æŒ‡é’ˆç½‘ç»œ

    - æ³¨æ„åŠ›ä½œä¸ºé€‰æ‹©
    - ç»„åˆä¼˜åŒ–
    - å¯å˜è¾“å‡ºå¤§å°
12. **`08_seq2seq_for_sets.ipynb`** - é›†åˆçš„åºåˆ—åˆ°åºåˆ—

    - æ’åˆ—ä¸å˜é›†åˆç¼–ç å™¨
    - è¯»å–-å¤„ç†-å†™å…¥æ¶æ„
    - æ— åºå…ƒç´ çš„æ³¨æ„åŠ›
    - æ’åºå’Œé›†åˆæ“ä½œ
    - æ¯”è¾ƒï¼šé¡ºåºæ•æ„Ÿ vs é¡ºåºä¸å˜
13. **`09_gpipe.ipynb`** - GPipe æµæ°´çº¿å¹¶è¡Œ

    - è·¨è®¾å¤‡çš„æ¨¡å‹åˆ†åŒº
    - æµæ°´çº¿åˆ©ç”¨çš„å¾®æ‰¹æ¬¡
    - å…ˆå‰å‘åè°ƒåº¦ (å…¨éƒ¨å‰å‘ï¼Œå…¨éƒ¨åå‘)
    - é‡è®¡ç®— (æ¢¯åº¦æ£€æŸ¥ç‚¹)
    - æ°”æ³¡æ—¶é—´åˆ†æ
    - è®­ç»ƒè¶…è¿‡å•è®¾å¤‡å†…å­˜çš„æ¨¡å‹

#### é«˜çº§ä¸»é¢˜

14. **`12_graph_neural_networks.ipynb`** - å›¾ç¥ç»ç½‘ç»œ

    - æ¶ˆæ¯ä¼ é€’æ¡†æ¶
    - å›¾å·ç§¯
    - åˆ†å­å±æ€§é¢„æµ‹
15. **`16_relational_reasoning.ipynb`** - å…³ç³»ç½‘ç»œ

    - æˆå¯¹å…³ç³»æ¨ç†
    - è§†è§‰é—®ç­” (Visual QA)
    - æ’åˆ—ä¸å˜æ€§
16. **`18_relational_rnn.ipynb`** - å…³ç³» RNN

    - å¸¦å…³ç³»è®°å¿†çš„ LSTM
    - è·¨è®°å¿†æ§½çš„å¤šå¤´è‡ªæ³¨æ„åŠ›
    - æ¶æ„æ¼”ç¤ºï¼ˆå‰å‘ä¼ æ’­ï¼‰
    - åºåˆ—æ¨ç†ä»»åŠ¡
    - **ç¬¬ 11 èŠ‚ï¼šæ‰‹åŠ¨åå‘ä¼ æ’­å®ç° (~1100 è¡Œ)**
    - æ‰€æœ‰ç»„ä»¶çš„å®Œæ•´æ¢¯åº¦è®¡ç®—
    - æ•°å€¼éªŒè¯çš„æ¢¯åº¦æ£€æŸ¥
17. **`20_neural_turing_machine.ipynb`** - è®°å¿†å¢å¼ºç½‘ç»œ

    - å†…å®¹å’Œä½ç½®å¯»å€
    - å¯å¾®åˆ†è¯»/å†™
    - å¤–éƒ¨è®°å¿†
18. **`21_ctc_speech.ipynb`** - CTC æŸå¤±ä¸è¯­éŸ³è¯†åˆ«

    - è”ç»“æ—¶åºåˆ†ç±»
    - æ— å¯¹é½è®­ç»ƒ
    - å‰å‘ç®—æ³•

#### ç”Ÿæˆæ¨¡å‹

19. **`17_variational_autoencoder.ipynb`** - VAE
    - ç”Ÿæˆå»ºæ¨¡
    - ELBO æŸå¤±
    - æ½œç©ºé—´å¯è§†åŒ–

#### ç°ä»£åº”ç”¨

20. **`27_multi_token_prediction.ipynb`** - å¤šä»¤ç‰Œé¢„æµ‹

    - é¢„æµ‹å¤šä¸ªæœªæ¥ä»¤ç‰Œ
    - 2-3 å€æ ·æœ¬æ•ˆç‡
    - æŠ•æœºè§£ç 
    - æ›´å¿«çš„è®­ç»ƒå’Œæ¨ç†
21. **`28_dense_passage_retrieval.ipynb`** - å¯†é›†æ£€ç´¢

    - åŒç¼–ç å™¨æ¶æ„
    - æ‰¹æ¬¡å†…è´Ÿæ ·æœ¬
    - è¯­ä¹‰æœç´¢
22. **`29_rag.ipynb`** - æ£€ç´¢å¢å¼ºç”Ÿæˆ

    - RAG-Sequence vs RAG-Token
    - ç»“åˆæ£€ç´¢ + ç”Ÿæˆ
    - çŸ¥è¯†é©±åŠ¨è¾“å‡º
23. **`30_lost_in_middle.ipynb`** - é•¿ä¸Šä¸‹æ–‡åˆ†æ

    - LLM ä¸­çš„ä½ç½®åå·®
    - U å‹æ€§èƒ½æ›²çº¿
    - æ–‡æ¡£æ’åºç­–ç•¥

#### ç¼©æ”¾ä¸ç†è®º

24. **`22_scaling_laws.ipynb`** - ç¼©æ”¾å®šå¾‹

    - å¹‚å¾‹å…³ç³»
    - è®¡ç®—æœ€ä¼˜è®­ç»ƒ
    - æ€§èƒ½é¢„æµ‹
25. **`23_mdl_principle.ipynb`** - æœ€å°æè¿°é•¿åº¦

    - ä¿¡æ¯è®ºæ¨¡å‹é€‰æ‹©
    - å‹ç¼© = ç†è§£
    - MDL vs AIC/BIC æ¯”è¾ƒ
    - ç¥ç»ç½‘ç»œæ¶æ„é€‰æ‹©
    - åŸºäº MDL çš„å‰ªæï¼ˆè¿æ¥åˆ°è®ºæ–‡ 5ï¼‰
    - Kolmogorov å¤æ‚æ€§é¢„è§ˆ
26. **`25_kolmogorov_complexity.ipynb`** - Kolmogorov å¤æ‚æ€§

    - K(x) = ç”Ÿæˆ x çš„æœ€çŸ­ç¨‹åº
    - éšæœºæ€§ = ä¸å¯å‹ç¼©æ€§
    - ç®—æ³•æ¦‚ç‡ (Solomonoff)
    - å½’çº³çš„é€šç”¨å…ˆéªŒ
    - ä¸ Shannon ç†µçš„è¿æ¥
    - å¥¥å¡å§†å‰ƒåˆ€çš„å½¢å¼åŒ–
    - ML çš„ç†è®ºåŸºç¡€
27. **`24_machine_super_intelligence.ipynb`** - é€šç”¨äººå·¥æ™ºèƒ½

    - **æ™ºèƒ½çš„å½¢å¼ç†è®º (Legg & Hutter)**
    - å¿ƒç†æµ‹é‡ g å› å­å’Œé€šç”¨æ™ºèƒ½ Î¥(Ï€)
    - åºåˆ—é¢„æµ‹çš„ Solomonoff å½’çº³
    - AIXIï¼šç†è®ºæœ€ä¼˜çš„ RL æ™ºèƒ½ä½“
    - è’™ç‰¹å¡æ´› AIXI (MC-AIXI) è¿‘ä¼¼
    - Kolmogorov å¤æ‚æ€§ä¼°è®¡
    - è·¨ç¯å¢ƒçš„æ™ºèƒ½æµ‹é‡
    - é€’å½’è‡ªæˆ‘æ”¹è¿›åŠ¨æ€
    - æ™ºèƒ½çˆ†ç‚¸åœºæ™¯
    - **6 ä¸ªç« èŠ‚ï¼šä»å¿ƒç†æµ‹é‡åˆ°è¶…çº§æ™ºèƒ½**
    - è¿æ¥è®ºæ–‡ #23 (MDL)ã€#25 (Kolmogorov)ã€#8 (DQN)
28. **`01_complexity_dynamics.ipynb`** - å¤æ‚æ€§ä¸ç†µ

    - ç»†èƒè‡ªåŠ¨æœº (Rule 30)
    - ç†µå¢é•¿
    - ä¸å¯é€†æ€§ï¼ˆåŸºç¡€ä»‹ç»ï¼‰
29. **`19_coffee_automaton.ipynb`** - å’–å•¡è‡ªåŠ¨æœºï¼ˆæ·±åº¦æ¢ç´¢ï¼‰

    - **ä¸å¯é€†æ€§çš„å…¨é¢æ¢ç´¢**
    - å’–å•¡æ··åˆå’Œæ‰©æ•£è¿‡ç¨‹
    - ç†µå¢é•¿å’Œç²—ç²’åŒ–
    - ç›¸ç©ºé—´å’Œ Liouville å®šç†
    - PoincarÃ© å›å½’å®šç†ï¼ˆe^N æ—¶é—´åä¼šé‡æ–°æ··åˆï¼ï¼‰
    - Maxwell å¦–å’Œ Landauer åŸç†
    - è®¡ç®—ä¸å¯é€†æ€§ï¼ˆå•å‘å‡½æ•°ã€å“ˆå¸Œï¼‰
    - æœºå™¨å­¦ä¹ ä¸­çš„ä¿¡æ¯ç“¶é¢ˆ
    - ç”Ÿç‰©ä¸å¯é€†æ€§ï¼ˆç”Ÿå‘½å’Œç¬¬äºŒå®šå¾‹ï¼‰
    - æ—¶é—´ç®­å¤´ï¼šåŸºæœ¬ vs æ¶Œç°
    - **10 ä¸ªå…¨é¢ç« èŠ‚æ¢ç´¢æ‰€æœ‰å°ºåº¦çš„ä¸å¯é€†æ€§**
30. **`26_cs231n_cnn_fundamentals.ipynb`** - CS231nï¼šä»ç¬¬ä¸€æ€§åŸç†çš„è§†è§‰

    - **çº¯ NumPy çš„å®Œæ•´è§†è§‰æµç¨‹**
    - k è¿‘é‚»åŸºçº¿
    - çº¿æ€§åˆ†ç±»å™¨ (SVM å’Œ Softmax)
    - ä¼˜åŒ– (SGDã€Momentumã€Adamã€å­¦ä¹ ç‡è°ƒåº¦)
    - å¸¦åå‘ä¼ æ’­çš„ 2 å±‚ç¥ç»ç½‘ç»œ
    - å·ç§¯å±‚ (convã€poolã€ReLU)
    - å®Œæ•´çš„ CNN æ¶æ„ (Mini-AlexNet)
    - å¯è§†åŒ–æŠ€æœ¯ï¼ˆæ»¤æ³¢å™¨ã€æ˜¾è‘—æ€§å›¾ï¼‰
    - è¿ç§»å­¦ä¹ åŸåˆ™
    - è°ƒä¼˜æŠ€å·§ï¼ˆå¥å…¨æ€§æ£€æŸ¥ã€è¶…å‚æ•°è°ƒä¼˜ã€ç›‘æ§ï¼‰
    - **10 ä¸ªç« èŠ‚è¦†ç›–æ•´ä¸ª CS231n è¯¾ç¨‹**
    - è¿æ¥è®ºæ–‡ #7 (AlexNet)ã€#10 (ResNet)ã€#11 (æ‰©å¼ å·ç§¯)

## Repository Structure

```
sutskever-30-implementations-zhCN/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ PROGRESS.md                         # Implementation progress tracking
â”œâ”€â”€ IMPLEMENTATION_TRACKS.md            # Detailed tracks for all 30 papers
â”‚
â”œâ”€â”€ 01_complexity_dynamics.ipynb        # Entropy & complexity
â”œâ”€â”€ 02_char_rnn_karpathy.ipynb         # Vanilla RNN
â”œâ”€â”€ 03_lstm_understanding.ipynb         # LSTM gates
â”œâ”€â”€ 04_rnn_regularization.ipynb         # Dropout for RNNs
â”œâ”€â”€ 05_neural_network_pruning.ipynb     # Pruning & MDL
â”œâ”€â”€ 06_pointer_networks.ipynb           # Attention pointers
â”œâ”€â”€ 07_alexnet_cnn.ipynb               # CNNs & AlexNet
â”œâ”€â”€ 08_seq2seq_for_sets.ipynb          # Permutation-invariant sets
â”œâ”€â”€ 09_gpipe.ipynb                     # Pipeline parallelism
â”œâ”€â”€ 10_resnet_deep_residual.ipynb      # Residual connections
â”œâ”€â”€ 11_dilated_convolutions.ipynb       # Multi-scale convolutions
â”œâ”€â”€ 12_graph_neural_networks.ipynb      # Message passing GNNs
â”œâ”€â”€ 13_attention_is_all_you_need.ipynb # Transformer architecture
â”œâ”€â”€ 14_bahdanau_attention.ipynb         # Original attention
â”œâ”€â”€ 15_identity_mappings_resnet.ipynb   # Pre-activation ResNet
â”œâ”€â”€ 16_relational_reasoning.ipynb       # Relation networks
â”œâ”€â”€ 17_variational_autoencoder.ipynb   # VAE
â”œâ”€â”€ 18_relational_rnn.ipynb             # Relational RNN
â”œâ”€â”€ 19_coffee_automaton.ipynb           # Irreversibility deep dive
â”œâ”€â”€ 20_neural_turing_machine.ipynb     # External memory
â”œâ”€â”€ 21_ctc_speech.ipynb                # CTC loss
â”œâ”€â”€ 22_scaling_laws.ipynb              # Empirical scaling
â”œâ”€â”€ 23_mdl_principle.ipynb             # MDL & compression
â”œâ”€â”€ 24_machine_super_intelligence.ipynb # Universal AI & AIXI
â”œâ”€â”€ 25_kolmogorov_complexity.ipynb     # K(x) & randomness
â”œâ”€â”€ 26_cs231n_cnn_fundamentals.ipynb    # Vision from first principles
â”œâ”€â”€ 27_multi_token_prediction.ipynb     # Multi-token prediction
â”œâ”€â”€ 28_dense_passage_retrieval.ipynb    # Dense retrieval
â”œâ”€â”€ 29_rag.ipynb                       # RAG architecture
â””â”€â”€ 30_lost_in_middle.ipynb            # Long context analysis
```

**All 30 papers implemented! (100% complete!) ğŸ‰**

## Learning Path

### Beginner Track (Start here!)

1. **Character RNN** (`02_char_rnn_karpathy.ipynb`) - Learn basic RNNs
2. **LSTM** (`03_lstm_understanding.ipynb`) - Understand gating mechanisms
3. **CNNs** (`07_alexnet_cnn.ipynb`) - Computer vision fundamentals
4. **ResNet** (`10_resnet_deep_residual.ipynb`) - Skip connections
5. **VAE** (`17_variational_autoencoder.ipynb`) - Generative models

### Intermediate Track

6. **RNN Regularization** (`04_rnn_regularization.ipynb`) - Better training
7. **Bahdanau Attention** (`14_bahdanau_attention.ipynb`) - Attention basics
8. **Pointer Networks** (`06_pointer_networks.ipynb`) - Attention as selection
9. **Seq2Seq for Sets** (`08_seq2seq_for_sets.ipynb`) - Permutation invariance
10. **CS231n** (`26_cs231n_cnn_fundamentals.ipynb`) - Complete vision pipeline (kNN â†’ CNNs)
11. **GPipe** (`09_gpipe.ipynb`) - Pipeline parallelism for large models
12. **Transformers** (`13_attention_is_all_you_need.ipynb`) - Modern architecture
13. **Dilated Convolutions** (`11_dilated_convolutions.ipynb`) - Receptive fields
14. **Scaling Laws** (`22_scaling_laws.ipynb`) - Understanding scale

### Advanced Track

15. **Pre-activation ResNet** (`15_identity_mappings_resnet.ipynb`) - Architecture details
16. **Graph Neural Networks** (`12_graph_neural_networks.ipynb`) - Graph learning
17. **Relation Networks** (`16_relational_reasoning.ipynb`) - Relational reasoning
18. **Neural Turing Machines** (`20_neural_turing_machine.ipynb`) - External memory
19. **CTC Loss** (`21_ctc_speech.ipynb`) - Speech recognition
20. **Dense Retrieval** (`28_dense_passage_retrieval.ipynb`) - Semantic search
21. **RAG** (`29_rag.ipynb`) - Retrieval-augmented generation
22. **Lost in the Middle** (`30_lost_in_middle.ipynb`) - Long context analysis

### Theory & Fundamentals

23. **MDL Principle** (`23_mdl_principle.ipynb`) - Model selection via compression
24. **Kolmogorov Complexity** (`25_kolmogorov_complexity.ipynb`) - Randomness & information
25. **Complexity Dynamics** (`01_complexity_dynamics.ipynb`) - Entropy & emergence
26. **Coffee Automaton** (`19_coffee_automaton.ipynb`) - Deep dive into irreversibility

## Key Insights from the Sutskever 30

### Architecture Evolution

- **RNN â†’ LSTM**: Gating solves vanishing gradients
- **Plain Networks â†’ ResNet**: Skip connections enable depth
- **RNN â†’ Transformer**: Attention enables parallelization
- **Fixed vocab â†’ Pointers**: Output can reference input

### Fundamental Mechanisms

- **Attention**: Differentiable selection mechanism
- **Residual Connections**: Gradient highways
- **Gating**: Learned information flow control
- **External Memory**: Separate storage from computation

### Training Insights

- **Scaling Laws**: Performance predictably improves with scale
- **Regularization**: Dropout, weight decay, data augmentation
- **Optimization**: Gradient clipping, learning rate schedules
- **Compute-Optimal**: Balance model size and training data

### Theoretical Foundations

- **Information Theory**: Compression, entropy, MDL
- **Complexity**: Kolmogorov complexity, power laws
- **Generative Modeling**: VAE, ELBO, latent spaces
- **Memory**: Differentiable data structures

## å®ç°ç†å¿µ

### ä¸ºä»€ä¹ˆä»…ä½¿ç”¨ NumPyï¼Ÿ

è¿™äº›å®ç°æœ‰æ„é¿å…ä½¿ç”¨ PyTorch/TensorFlow ä»¥ï¼š

- **åŠ æ·±ç†è§£**ï¼šçœ‹æ¸…æ¥šæ¡†æ¶æŠ½è±¡çš„å†…å®¹
- **æ•™å­¦æ¸…æ™°åº¦**ï¼šæ— é­”æ³•ï¼Œæ¯é¡¹æ“ä½œéƒ½æ˜¾å¼
- **æ ¸å¿ƒæ¦‚å¿µ**ï¼šä¸“æ³¨äºç®—æ³•è€Œéæ¡†æ¶ API
- **å¯è¿ç§»çŸ¥è¯†**ï¼šåŸåˆ™é€‚ç”¨äºä»»ä½•æ¡†æ¶

### åˆæˆæ•°æ®æ–¹æ³•

æ¯ä¸ª notebook ç”Ÿæˆè‡ªå·±çš„æ•°æ®ä»¥ï¼š

- **ç«‹å³æ‰§è¡Œ**ï¼šæ— éœ€ä¸‹è½½æ•°æ®é›†
- **å—æ§å®éªŒ**ï¼šç†è§£ç®€å•æƒ…å†µä¸‹çš„è¡Œä¸º
- **æ¦‚å¿µä¸“æ³¨**ï¼šæ•°æ®ä¸ä¼šæ¨¡ç³Šç®—æ³•
- **å¿«é€Ÿè¿­ä»£**ï¼šç«‹å³ä¿®æ”¹å’Œé‡æ–°è¿è¡Œ

## æ‰©å±•ä¸åç»­æ­¥éª¤

### åŸºäºè¿™äº›å®ç°æ„å»º

ç†è§£æ ¸å¿ƒæ¦‚å¿µåï¼Œå°è¯•ï¼š

1. **æ‰©å±•**ï¼šåœ¨ PyTorch/JAX ä¸­å®ç°ä»¥å¤„ç†çœŸå®æ•°æ®é›†
2. **ç»„åˆæŠ€æœ¯**ï¼šä¾‹å¦‚ï¼ŒResNet + Attention
3. **ç°ä»£å˜ä½“**ï¼š
   - RNN â†’ GRU â†’ Transformer
   - VAE â†’ Î²-VAE â†’ VQ-VAE
   - ResNet â†’ ResNeXt â†’ EfficientNet
4. **åº”ç”¨**ï¼šåº”ç”¨äºå®é™…é—®é¢˜

### ç ”ç©¶æ–¹å‘

Sutskever 30 æŒ‡å‘ï¼š

- ç¼©æ”¾ï¼ˆæ›´å¤§çš„æ¨¡å‹ã€æ›´å¤šæ•°æ®ï¼‰
- æ•ˆç‡ï¼ˆç¨€ç–æ¨¡å‹ã€é‡åŒ–ï¼‰
- èƒ½åŠ›ï¼ˆæ¨ç†ã€å¤šæ¨¡æ€ï¼‰
- ç†è§£ï¼ˆå¯è§£é‡Šæ€§ã€ç†è®ºï¼‰

## èµ„æº

### åŸå§‹è®ºæ–‡

å®Œæ•´å¼•ç”¨å’Œé“¾æ¥è§ `IMPLEMENTATION_TRACKS.md`

### å»¶ä¼¸é˜…è¯»

- [Ilya Sutskever çš„é˜…è¯»åˆ—è¡¨ (GitHub)](https://github.com/dzyim/ilya-sutskever-recommended-reading)
- [Aman çš„ AI æœŸåˆŠ - Sutskever 30 å…¥é—¨](https://aman.ai/primers/ai/top-30-papers/)
- [å¸¦æ³¨é‡Šçš„ Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)
- [Andrej Karpathy çš„åšå®¢](http://karpathy.github.io/)

### è¯¾ç¨‹

- Stanford CS231nï¼šå·ç§¯ç¥ç»ç½‘ç»œ
- Stanford CS224nï¼šæ·±åº¦å­¦ä¹ è‡ªç„¶è¯­è¨€å¤„ç†
- MIT 6.S191ï¼šæ·±åº¦å­¦ä¹ å¯¼è®º

## è´¡çŒ®

è¿™äº›å®ç°æ˜¯æ•™è‚²æ€§çš„ï¼Œå¯ä»¥æ”¹è¿›ï¼è€ƒè™‘ï¼š

- æ·»åŠ æ›´å¤šå¯è§†åŒ–
- å®ç°ç¼ºå¤±çš„è®ºæ–‡
- æ”¹è¿›è§£é‡Š
- å‘ç°é”™è¯¯
- æ·»åŠ ä¸æ¡†æ¶å®ç°çš„æ¯”è¾ƒ

## è®¸å¯è¯

æ•™è‚²ç”¨é€”ã€‚åŸå§‹ç ”ç©¶å¼•ç”¨è¯·å‚é˜…å„è®ºæ–‡ã€‚

## è‡´è°¢

- **Ilya Sutskever**ï¼šç­–åˆ’äº†è¿™ä¸ªåŸºæœ¬é˜…è¯»åˆ—è¡¨
- **è®ºæ–‡ä½œè€…**ï¼šä»–ä»¬çš„åŸºç¡€æ€§è´¡çŒ®
- **ç¤¾åŒº**ï¼šè®©è¿™äº›æƒ³æ³•å˜å¾—æ˜“äºç†è§£

---

## æœ€æ–°æ·»åŠ ï¼ˆ2025 å¹´ 12 æœˆï¼‰

### æœ€è¿‘å®ç°ï¼ˆ21 ç¯‡æ–°è®ºæ–‡ï¼ï¼‰

- âœ… **è®ºæ–‡ 4**ï¼šRNN æ­£åˆ™åŒ–ï¼ˆå˜åˆ†ä¸¢å¼ƒï¼‰
- âœ… **è®ºæ–‡ 5**ï¼šç¥ç»ç½‘ç»œå‰ªæï¼ˆMDLã€90%+ ç¨€ç–æ€§ï¼‰
- âœ… **è®ºæ–‡ 7**ï¼šAlexNetï¼ˆä»é›¶å®ç° CNNï¼‰
- âœ… **è®ºæ–‡ 8**ï¼šé›†åˆçš„åºåˆ—åˆ°åºåˆ—ï¼ˆæ’åˆ—ä¸å˜æ€§ã€æ³¨æ„åŠ›æ± åŒ–ï¼‰
- âœ… **è®ºæ–‡ 9**ï¼šGPipeï¼ˆæµæ°´çº¿å¹¶è¡Œã€å¾®æ‰¹æ¬¡ã€é‡è®¡ç®—ï¼‰
- âœ… **è®ºæ–‡ 19**ï¼šå’–å•¡è‡ªåŠ¨æœºï¼ˆæ·±å…¥æ¢è®¨ä¸å¯é€†æ€§ã€ç†µã€Landauer åŸç†ï¼‰
- âœ… **è®ºæ–‡ 26**ï¼šCS231nï¼ˆå®Œæ•´è§†è§‰æµç¨‹ï¼škNN â†’ CNNï¼Œå…¨éƒ¨ä½¿ç”¨ NumPyï¼‰
- âœ… **è®ºæ–‡ 11**ï¼šæ‰©å¼ å·ç§¯ï¼ˆå¤šå°ºåº¦ï¼‰
- âœ… **è®ºæ–‡ 12**ï¼šå›¾ç¥ç»ç½‘ç»œï¼ˆæ¶ˆæ¯ä¼ é€’ï¼‰
- âœ… **è®ºæ–‡ 14**ï¼šBahdanau æ³¨æ„åŠ›ï¼ˆåŸå§‹æ³¨æ„åŠ›ï¼‰
- âœ… **è®ºæ–‡ 15**ï¼šResNet æ’ç­‰æ˜ å°„ï¼ˆé¢„æ¿€æ´»ï¼‰
- âœ… **è®ºæ–‡ 16**ï¼šå…³ç³»æ¨ç†ï¼ˆå…³ç³»ç½‘ç»œï¼‰
- âœ… **è®ºæ–‡ 18**ï¼šå…³ç³» RNNï¼ˆå…³ç³»è®°å¿† + ç¬¬ 11 èŠ‚ï¼šæ‰‹åŠ¨åå‘ä¼ æ’­ ~1100 è¡Œï¼‰
- âœ… **è®ºæ–‡ 21**ï¼šDeep Speech 2ï¼ˆCTC æŸå¤±ï¼‰
- âœ… **è®ºæ–‡ 23**ï¼šMDL åŸåˆ™ï¼ˆå‹ç¼©ã€æ¨¡å‹é€‰æ‹©ï¼Œè¿æ¥åˆ°è®ºæ–‡ 5 å’Œ 25ï¼‰
- âœ… **è®ºæ–‡ 24**ï¼šæœºå™¨è¶…çº§æ™ºèƒ½ï¼ˆé€šç”¨ AIã€AIXIã€Solomonoff å½’çº³ã€æ™ºèƒ½åº¦é‡ã€é€’å½’è‡ªæˆ‘æ”¹è¿›ï¼‰
- âœ… **è®ºæ–‡ 25**ï¼šKolmogorov å¤æ‚æ€§ï¼ˆéšæœºæ€§ã€ç®—æ³•æ¦‚ç‡ã€ç†è®ºåŸºç¡€ï¼‰
- âœ… **è®ºæ–‡ 27**ï¼šå¤šä»¤ç‰Œé¢„æµ‹ï¼ˆ2-3 å€æ ·æœ¬æ•ˆç‡ï¼‰
- âœ… **è®ºæ–‡ 28**ï¼šå¯†é›†æ®µè½æ£€ç´¢ï¼ˆåŒç¼–ç å™¨ï¼‰
- âœ… **è®ºæ–‡ 29**ï¼šRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰
- âœ… **è®ºæ–‡ 30**ï¼šè¿·å¤±åœ¨ä¸­é—´ï¼ˆé•¿ä¸Šä¸‹æ–‡ï¼‰

## å¿«é€Ÿå‚è€ƒï¼šå®ç°å¤æ‚åº¦

### å¯ä»¥åœ¨ä¸€ä¸ªä¸‹åˆå®ç°

- âœ… å­—ç¬¦çº§ RNN
- âœ… LSTM
- âœ… ResNet
- âœ… ç®€å•çš„ VAE
- âœ… æ‰©å¼ å·ç§¯

### å‘¨æœ«é¡¹ç›®

- âœ… Transformer
- âœ… æŒ‡é’ˆç½‘ç»œ
- âœ… å›¾ç¥ç»ç½‘ç»œ
- âœ… å…³ç³»ç½‘ç»œ
- âœ… ç¥ç»å›¾çµæœº
- âœ… CTC æŸå¤±
- âœ… å¯†é›†æ£€ç´¢

### ä¸€å‘¨æ·±åº¦æ¢ç´¢

- âœ… å®Œæ•´çš„ RAG ç³»ç»Ÿ
- âš ï¸ å¤§è§„æ¨¡å®éªŒ
- âš ï¸ è¶…å‚æ•°ä¼˜åŒ–

---

**"å¦‚æœä½ çœŸçš„å­¦ä¼šäº†æ‰€æœ‰è¿™äº›ï¼Œä½ å°†äº†è§£ä»Šå¤© 90% é‡è¦çš„å†…å®¹ã€‚"** - Ilya Sutskever

ç¥å­¦ä¹ æ„‰å¿«ï¼ğŸš€
